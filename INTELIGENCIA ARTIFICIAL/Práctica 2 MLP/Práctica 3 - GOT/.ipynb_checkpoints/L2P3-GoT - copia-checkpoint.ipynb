{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Aquí se importan las librerias que se van a utiliar\n",
    "\n",
    "%reset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "import keras.optimizers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función para imprimir la supervivencia de los personajes\n",
    "def Imprimir_Prediccion_Vida(personajes, probabilidad):\n",
    "    for i in range(0, personajes.shape[0]):\n",
    "        print(\"- \" + str(personajes[i]) + \": \" + str(round(probabilidad[i][0],2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función para imprimir la supervivencia de los personajes\n",
    "def Imprimir_Medias_Pesos(nombres, pesos):\n",
    "    for i in range(0, nombres.shape[0]):\n",
    "        print(\"- \" + str(nombres[i]) + \": \" + str(pesos[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recolección datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del fichero de datos de entrenamiento y validación\n",
    "datos = pd.read_csv('../Datos/got.csv')\n",
    "\n",
    "# Recolección de información de entrada para la red neuronal (especificada en el enunciado)\n",
    "genero = datos.loc[:,'male']\n",
    "aparicion_libro_1 = datos.loc[:,'book1']\n",
    "aparicion_libro_2 = datos.loc[:,'book2']\n",
    "aparicion_libro_3 = datos.loc[:,'book3']\n",
    "aparicion_libro_4 = datos.loc[:,'book4']\n",
    "aparicion_libro_5 = datos.loc[:,'book5']\n",
    "casado = datos.loc[:,'isMarried']\n",
    "noble = datos.loc[:,'isNoble']\n",
    "numero_personas_cercanas_muertas = datos.loc[:,'numDeadRelations']\n",
    "popular = datos.loc[:,'isPopular']\n",
    "    \n",
    "# Unión de la información de entrada\n",
    "entrada = np.array([[genero],[aparicion_libro_1],[aparicion_libro_2],[aparicion_libro_3],[aparicion_libro_4],\n",
    "        [aparicion_libro_5],[casado],[noble],[numero_personas_cercanas_muertas],[popular]])\n",
    "\n",
    "entrada = entrada.transpose().reshape(1946, 10)\n",
    "\n",
    "# Recolección de la salida esperada de la red neuronal\n",
    "salida_esperada = np.array(datos.loc[:,'alive'])\n",
    "\n",
    "# Conjunto entrenamiento\n",
    "entrada_entrenamiento = entrada[:1750,:]\n",
    "salida_entrenamiento = salida_esperada[:1750]\n",
    "\n",
    "# Conjunto validación\n",
    "entrada_validacion = entrada[1750:,:]\n",
    "salida_validacion = salida_esperada[1750:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recolección datos de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del fichero de datos de entrenamiento\n",
    "datos_pre = pd.read_csv('../Datos/got_predicciones.csv')\n",
    "\n",
    "# Recolección de información de entrada para la red neuronal\n",
    "genero = datos_pre.loc[:,'male']\n",
    "aparicion_libro_1 = datos_pre.loc[:,'book1']\n",
    "aparicion_libro_2 = datos_pre.loc[:,'book2']\n",
    "aparicion_libro_3 = datos_pre.loc[:,'book3']\n",
    "aparicion_libro_4 = datos_pre.loc[:,'book4']\n",
    "aparicion_libro_5 = datos_pre.loc[:,'book5']\n",
    "casado = datos_pre.loc[:,'isMarried']\n",
    "noble = datos_pre.loc[:,'isNoble']\n",
    "numero_personas_cercanas_muertas = datos_pre.loc[:,'numDeadRelations']\n",
    "popular = datos_pre.loc[:,'isPopular']\n",
    "    \n",
    "# Unión de la información de entrada\n",
    "entrada_pre = np.array([[genero],[aparicion_libro_1],[aparicion_libro_2],[aparicion_libro_3],[aparicion_libro_4],\n",
    "        [aparicion_libro_5],[casado],[noble],[numero_personas_cercanas_muertas],[popular]])\n",
    "\n",
    "entrada_pre = entrada_pre.transpose().reshape(5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación 1. Entrenamiento GoT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Entrenamiento realizado con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Configuración de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(units=260, activation='relu', input_dim=10))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=0.001))\n",
    "\n",
    "model.fit(entrada, salida_esperada, epochs=500, verbose=0)\n",
    "\n",
    "print(\"> Entrenamiento realizado con éxito.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error del conjunto de validación es de: 5.98%\n"
     ]
    }
   ],
   "source": [
    "error = model.evaluate(entrada_validacion, salida_validacion, verbose = 0)\n",
    "\n",
    "print(\"El error del conjunto de validación es de: %.2f%%\" % (error*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación 2. Predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de supervivencia: \n",
      "\n",
      "- Tommen Baratheon: 10.68%\n",
      "- Daenerys Targaryen: 9.65%\n",
      "- Coldhands: 75.6%\n",
      "- Othell Yarwyck: 53.76%\n",
      "- Roland Crakehall (Kingsguard): 38.33%\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilidad de supervivencia: \\n\")\n",
    "\n",
    "Imprimir_Prediccion_Vida(datos_pre['name'], model.predict(entrada_pre) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorización de los pesos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos medios por entrada\n",
      "------------------------\n",
      " Característica    Peso \n",
      "------------------------\n",
      "- male: [-0.09484062]\n",
      "- book1: [-0.06475119]\n",
      "- book2: [-0.06631739]\n",
      "- book3: [-0.06302416]\n",
      "- book4: [-0.04617877]\n",
      "- book5: [-0.07527734]\n",
      "- isMarried: [-0.048817]\n",
      "- isNoble: [-0.06785083]\n",
      "- numDeadRelations: [-0.07345459]\n",
      "- isPopular: [ 0.04211986]\n"
     ]
    }
   ],
   "source": [
    "pesos_entrada = model.get_weights()[0]\n",
    "\n",
    "nombres_entrada = np.array(['male','book1','book2','book3',\n",
    "                            'book4','book5','isMarried','isNoble',\n",
    "                            'numDeadRelations','isPopular'])\n",
    "\n",
    "medias = np.array([ [np.average(pesos_entrada[0])], [np.average(pesos_entrada[1])], [np.average(pesos_entrada[2])],\n",
    "                    [np.average(pesos_entrada[3])], [np.average(pesos_entrada[4])], [np.average(pesos_entrada[5])],\n",
    "                    [np.average(pesos_entrada[6])], [np.average(pesos_entrada[7])], [np.average(pesos_entrada[8])],\n",
    "                    [np.average(pesos_entrada[9])]])\n",
    "\n",
    "print(\"Pesos medios por entrada\")\n",
    "print(\"------------------------\")\n",
    "print(\" Característica    Peso \")\n",
    "print(\"------------------------\")\n",
    "\n",
    "Imprimir_Medias_Pesos(nombres_entrada, medias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La característica isPopular es la que más tiende a 0, por lo que es la menos relevante para la red.\n",
    "\n",
    "#### La siguiente red predice también la probabilidad de supervivencia de los personajes pero sin la característica isPopular. Debería dar resultados similares pero no iguales, aunque afecte poco a la predicción, algo si que afecta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención del fichero de datos de entrenamiento\n",
    "datos = pd.read_csv('../Datos/got.csv')\n",
    "\n",
    "# Recolección de información de entrada para la red neuronal\n",
    "genero = datos.loc[:,'male']\n",
    "aparicion_libro_1 = datos.loc[:,'book1']\n",
    "aparicion_libro_2 = datos.loc[:,'book2']\n",
    "aparicion_libro_3 = datos.loc[:,'book3']\n",
    "aparicion_libro_4 = datos.loc[:,'book4']\n",
    "aparicion_libro_5 = datos.loc[:,'book5']\n",
    "casado = datos.loc[:,'isMarried']\n",
    "noble = datos.loc[:,'isNoble']\n",
    "numero_personas_cercanas_muertas = datos.loc[:,'numDeadRelations']\n",
    "    \n",
    "# Unión de la información de entrada\n",
    "entrada = np.array([[genero],[aparicion_libro_1],[aparicion_libro_2],[aparicion_libro_3],[aparicion_libro_4],\n",
    "        [aparicion_libro_5],[casado],[noble],[numero_personas_cercanas_muertas]])\n",
    "\n",
    "entrada = entrada.transpose().reshape(1946, 9)\n",
    "\n",
    "# Recolección de la salida esperada de la red neuronal\n",
    "salida_esperada = np.array(datos.loc[:,'alive'])\n",
    "\n",
    "# Conjunto entrenamiento\n",
    "entrada_entrenamiento = entrada[:1750,:]\n",
    "salida_entrenamiento = salida_esperada[:1750]\n",
    "\n",
    "# Conjunto validación\n",
    "entrada_validacion = entrada[1750:,:]\n",
    "salida_validacion = salida_esperada[1750:]\n",
    "\n",
    "# Configuración de la red neuronal\n",
    "model_sin_isPopular = Sequential()\n",
    "model_sin_isPopular.add(Dense(units=260, activation='relu', input_dim=9))\n",
    "model_sin_isPopular.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model_sin_isPopular.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=0.001))\n",
    "\n",
    "model_sin_isPopular.fit(entrada_entrenamiento, salida_entrenamiento, epochs=500, verbose=0)\n",
    "\n",
    "error = model_sin_isPopular.evaluate(entrada_validacion, salida_validacion, verbose = 0)\n",
    "\n",
    "print(\"El error del conjunto de validación es de: %.2f%%\" % (error*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora probamos a modificar las características más relevantes para demostrar que así lo son y forzar que otro personaje muera.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención del fichero de datos de entrenamiento\n",
    "datos_pre = pd.read_csv('../Datos/got_predicciones_modificado1.csv')\n",
    "\n",
    "# Recolección de información de entrada para la red neuronal\n",
    "genero = datos_pre.loc[:,'male']\n",
    "aparicion_libro_1 = datos_pre.loc[:,'book1']\n",
    "aparicion_libro_2 = datos_pre.loc[:,'book2']\n",
    "aparicion_libro_3 = datos_pre.loc[:,'book3']\n",
    "aparicion_libro_4 = datos_pre.loc[:,'book4']\n",
    "aparicion_libro_5 = datos_pre.loc[:,'book5']\n",
    "casado = datos_pre.loc[:,'isMarried']\n",
    "noble = datos_pre.loc[:,'isNoble']\n",
    "numero_personas_cercanas_muertas = datos_pre.loc[:,'numDeadRelations']\n",
    "popular = datos_pre.loc[:,'isPopular']\n",
    "    \n",
    "# Unión de la información de entrada\n",
    "entrada_pre = np.array([[genero],[aparicion_libro_1],[aparicion_libro_2],[aparicion_libro_3],[aparicion_libro_4],\n",
    "        [aparicion_libro_5],[casado],[noble],[numero_personas_cercanas_muertas],[popular]])\n",
    "\n",
    "entrada_pre = entrada_pre.transpose().reshape(5, 10)\n",
    "\n",
    "print(\"Probabilidad de supervivencia: \\n\")\n",
    "Imprimir_Prediccion_Vida(datos_pre['name'], model.predict(entrada_pre) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
