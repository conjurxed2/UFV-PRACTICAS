{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# Aquí se importan las librerias que se van a utiliar\n",
    "\n",
    "%reset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "import keras.optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función para imprimir la supervivencia de los personajes\n",
    "def Imprimir_Prediccion_Vida(personajes, probabilidad):\n",
    "    for i in range(0, personajes.shape[0]):\n",
    "        print(\"- \" + str(personajes[i]) + \": \" + str(round(probabilidad[i][0],2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función para imprimir la supervivencia de los personajes\n",
    "def Imprimir_Medias_Pesos(nombres, pesos):\n",
    "    for i in range(0, nombres.shape[0]):\n",
    "        print(\"- \" + str(nombres[i]) + \": \" + str(pesos[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recolección datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del fichero de datos de entrenamiento y validación\n",
    "datos = pd.read_csv('../Datos/got.csv')\n",
    "\n",
    "# Recolección de información de entrada para la red neuronal (especificada en el enunciado)\n",
    "genero = datos.loc[:,'male']\n",
    "aparicion_libro_1 = datos.loc[:,'book1']\n",
    "aparicion_libro_2 = datos.loc[:,'book2']\n",
    "aparicion_libro_3 = datos.loc[:,'book3']\n",
    "aparicion_libro_4 = datos.loc[:,'book4']\n",
    "aparicion_libro_5 = datos.loc[:,'book5']\n",
    "casado = datos.loc[:,'isMarried']\n",
    "noble = datos.loc[:,'isNoble']\n",
    "numero_personas_cercanas_muertas = datos.loc[:,'numDeadRelations']\n",
    "popular = datos.loc[:,'isPopular']\n",
    "    \n",
    "# Unión de la información de entrada\n",
    "entrada = np.array([[genero],[aparicion_libro_1],[aparicion_libro_2],[aparicion_libro_3],[aparicion_libro_4],\n",
    "        [aparicion_libro_5],[casado],[noble],[numero_personas_cercanas_muertas],[popular]])\n",
    "\n",
    "# Recolocación\n",
    "entrada = entrada.transpose().reshape(1946, 10)\n",
    "\n",
    "# Recolección de la salida esperada de la red neuronal\n",
    "salida_esperada = np.array(datos.loc[:,'alive'])\n",
    "\n",
    "# Conjunto entrenamiento\n",
    "entrada_entrenamiento = entrada[:1750,:]\n",
    "salida_entrenamiento = salida_esperada[:1750]\n",
    "\n",
    "# Conjunto validación\n",
    "entrada_validacion = entrada[1750:,:]\n",
    "salida_validacion = salida_esperada[1750:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recolección datos de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del fichero de datos de entrenamiento\n",
    "datos_pre = pd.read_csv('../Datos/got_predicciones.csv')\n",
    "\n",
    "# Recolección de información de entrada para la red neuronal\n",
    "genero = datos_pre.loc[:,'male']\n",
    "aparicion_libro_1 = datos_pre.loc[:,'book1']\n",
    "aparicion_libro_2 = datos_pre.loc[:,'book2']\n",
    "aparicion_libro_3 = datos_pre.loc[:,'book3']\n",
    "aparicion_libro_4 = datos_pre.loc[:,'book4']\n",
    "aparicion_libro_5 = datos_pre.loc[:,'book5']\n",
    "casado = datos_pre.loc[:,'isMarried']\n",
    "noble = datos_pre.loc[:,'isNoble']\n",
    "numero_personas_cercanas_muertas = datos_pre.loc[:,'numDeadRelations']\n",
    "popular = datos_pre.loc[:,'isPopular']\n",
    "    \n",
    "# Unión de la información de entrada\n",
    "entrada_pre = np.array([[genero],[aparicion_libro_1],[aparicion_libro_2],[aparicion_libro_3],[aparicion_libro_4],\n",
    "        [aparicion_libro_5],[casado],[noble],[numero_personas_cercanas_muertas],[popular]])\n",
    "\n",
    "# Recolocación\n",
    "entrada_pre = entrada_pre.transpose().reshape(5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación 1. Entrenamiento GoT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1750 samples, validate on 196 samples\n",
      "Epoch 1/200\n",
      "1750/1750 [==============================] - 0s 175us/step - loss: 0.0801 - acc: 0.0017 - val_loss: 0.0943 - val_acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      "1750/1750 [==============================] - 0s 35us/step - loss: 0.0613 - acc: 0.0017 - val_loss: 0.0895 - val_acc: 0.0051\n",
      "Epoch 3/200\n",
      "1750/1750 [==============================] - 0s 43us/step - loss: 0.0570 - acc: 0.0011 - val_loss: 0.0909 - val_acc: 0.0051\n",
      "Epoch 4/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0558 - acc: 0.0017 - val_loss: 0.0898 - val_acc: 0.0102\n",
      "Epoch 5/200\n",
      "1750/1750 [==============================] - 0s 34us/step - loss: 0.0553 - acc: 0.0017 - val_loss: 0.0882 - val_acc: 0.0102\n",
      "Epoch 6/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0544 - acc: 0.0017 - val_loss: 0.0883 - val_acc: 0.0102\n",
      "Epoch 7/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0541 - acc: 0.0017 - val_loss: 0.0865 - val_acc: 0.0102\n",
      "Epoch 8/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0532 - acc: 0.0017 - val_loss: 0.0863 - val_acc: 0.0102\n",
      "Epoch 9/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0527 - acc: 0.0023 - val_loss: 0.0880 - val_acc: 0.0102\n",
      "Epoch 10/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0524 - acc: 0.0023 - val_loss: 0.0851 - val_acc: 0.0102\n",
      "Epoch 11/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0522 - acc: 0.0023 - val_loss: 0.0841 - val_acc: 0.0102\n",
      "Epoch 12/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0519 - acc: 0.0023 - val_loss: 0.0832 - val_acc: 0.0102\n",
      "Epoch 13/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0519 - acc: 0.0023 - val_loss: 0.0850 - val_acc: 0.0102\n",
      "Epoch 14/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0518 - acc: 0.0023 - val_loss: 0.0861 - val_acc: 0.0102\n",
      "Epoch 15/200\n",
      "1750/1750 [==============================] - 0s 35us/step - loss: 0.0516 - acc: 0.0023 - val_loss: 0.0846 - val_acc: 0.0102\n",
      "Epoch 16/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0510 - acc: 0.0023 - val_loss: 0.0877 - val_acc: 0.0102\n",
      "Epoch 17/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0511 - acc: 0.0023 - val_loss: 0.0839 - val_acc: 0.0102\n",
      "Epoch 18/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0509 - acc: 0.0023 - val_loss: 0.0841 - val_acc: 0.0102\n",
      "Epoch 19/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0508 - acc: 0.0023 - val_loss: 0.0813 - val_acc: 0.0102\n",
      "Epoch 20/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0509 - acc: 0.0023 - val_loss: 0.0828 - val_acc: 0.0102\n",
      "Epoch 21/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0507 - acc: 0.0023 - val_loss: 0.0817 - val_acc: 0.0102\n",
      "Epoch 22/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0505 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 23/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0505 - acc: 0.0023 - val_loss: 0.0819 - val_acc: 0.0102\n",
      "Epoch 24/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0504 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 25/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0503 - acc: 0.0023 - val_loss: 0.0838 - val_acc: 0.0102\n",
      "Epoch 26/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0502 - acc: 0.0023 - val_loss: 0.0816 - val_acc: 0.0102\n",
      "Epoch 27/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0503 - acc: 0.0023 - val_loss: 0.0822 - val_acc: 0.0102\n",
      "Epoch 28/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0503 - acc: 0.0023 - val_loss: 0.0833 - val_acc: 0.0102\n",
      "Epoch 29/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0502 - acc: 0.0023 - val_loss: 0.0821 - val_acc: 0.0102\n",
      "Epoch 30/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0507 - acc: 0.0023 - val_loss: 0.0797 - val_acc: 0.0102\n",
      "Epoch 31/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0501 - acc: 0.0023 - val_loss: 0.0821 - val_acc: 0.0102\n",
      "Epoch 32/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0500 - acc: 0.0023 - val_loss: 0.0812 - val_acc: 0.0102\n",
      "Epoch 33/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0498 - acc: 0.0023 - val_loss: 0.0813 - val_acc: 0.0102\n",
      "Epoch 34/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0497 - acc: 0.0023 - val_loss: 0.0800 - val_acc: 0.0102\n",
      "Epoch 35/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0497 - acc: 0.0023 - val_loss: 0.0826 - val_acc: 0.0102\n",
      "Epoch 36/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0495 - acc: 0.0023 - val_loss: 0.0795 - val_acc: 0.0102\n",
      "Epoch 37/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0496 - acc: 0.0023 - val_loss: 0.0802 - val_acc: 0.0102\n",
      "Epoch 38/200\n",
      "1750/1750 [==============================] - 0s 32us/step - loss: 0.0496 - acc: 0.0023 - val_loss: 0.0825 - val_acc: 0.0102\n",
      "Epoch 39/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0497 - acc: 0.0023 - val_loss: 0.0803 - val_acc: 0.0102\n",
      "Epoch 40/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0497 - acc: 0.0023 - val_loss: 0.0797 - val_acc: 0.0102\n",
      "Epoch 41/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0493 - acc: 0.0023 - val_loss: 0.0794 - val_acc: 0.0102\n",
      "Epoch 42/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0494 - acc: 0.0023 - val_loss: 0.0835 - val_acc: 0.0102\n",
      "Epoch 43/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0491 - acc: 0.0023 - val_loss: 0.0796 - val_acc: 0.0102\n",
      "Epoch 44/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0492 - acc: 0.0023 - val_loss: 0.0795 - val_acc: 0.0102\n",
      "Epoch 45/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0493 - acc: 0.0023 - val_loss: 0.0820 - val_acc: 0.0102\n",
      "Epoch 46/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0491 - acc: 0.0023 - val_loss: 0.0813 - val_acc: 0.0102\n",
      "Epoch 47/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0492 - acc: 0.0023 - val_loss: 0.0812 - val_acc: 0.0102\n",
      "Epoch 48/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0494 - acc: 0.0023 - val_loss: 0.0799 - val_acc: 0.0102\n",
      "Epoch 49/200\n",
      "1750/1750 [==============================] - 0s 35us/step - loss: 0.0494 - acc: 0.0023 - val_loss: 0.0800 - val_acc: 0.0102\n",
      "Epoch 50/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0492 - acc: 0.0023 - val_loss: 0.0802 - val_acc: 0.0102\n",
      "Epoch 51/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0796 - val_acc: 0.0102\n",
      "Epoch 52/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0491 - acc: 0.0023 - val_loss: 0.0804 - val_acc: 0.0102\n",
      "Epoch 53/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0491 - acc: 0.0023 - val_loss: 0.0802 - val_acc: 0.0102\n",
      "Epoch 54/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0490 - acc: 0.0023 - val_loss: 0.0795 - val_acc: 0.0102\n",
      "Epoch 55/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0491 - acc: 0.0023 - val_loss: 0.0808 - val_acc: 0.0102\n",
      "Epoch 56/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0490 - acc: 0.0023 - val_loss: 0.0805 - val_acc: 0.0102\n",
      "Epoch 57/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0491 - acc: 0.0023 - val_loss: 0.0795 - val_acc: 0.0102\n",
      "Epoch 58/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0792 - val_acc: 0.0102\n",
      "Epoch 59/200\n",
      "1750/1750 [==============================] - 0s 36us/step - loss: 0.0490 - acc: 0.0023 - val_loss: 0.0815 - val_acc: 0.0102\n",
      "Epoch 60/200\n",
      "1750/1750 [==============================] - 0s 37us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0787 - val_acc: 0.0102\n",
      "Epoch 61/200\n",
      "1750/1750 [==============================] - 0s 37us/step - loss: 0.0485 - acc: 0.0023 - val_loss: 0.0787 - val_acc: 0.0102\n",
      "Epoch 62/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0804 - val_acc: 0.0102\n",
      "Epoch 63/200\n",
      "1750/1750 [==============================] - 0s 39us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0837 - val_acc: 0.0102\n",
      "Epoch 64/200\n",
      "1750/1750 [==============================] - 0s 37us/step - loss: 0.0488 - acc: 0.0023 - val_loss: 0.0788 - val_acc: 0.0102\n",
      "Epoch 65/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0488 - acc: 0.0023 - val_loss: 0.0794 - val_acc: 0.0102\n",
      "Epoch 66/200\n",
      "1750/1750 [==============================] - 0s 38us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0803 - val_acc: 0.0102\n",
      "Epoch 67/200\n",
      "1750/1750 [==============================] - 0s 36us/step - loss: 0.0492 - acc: 0.0023 - val_loss: 0.0798 - val_acc: 0.0102\n",
      "Epoch 68/200\n",
      "1750/1750 [==============================] - 0s 34us/step - loss: 0.0488 - acc: 0.0023 - val_loss: 0.0818 - val_acc: 0.0102\n",
      "Epoch 69/200\n",
      "1750/1750 [==============================] - 0s 38us/step - loss: 0.0485 - acc: 0.0023 - val_loss: 0.0801 - val_acc: 0.0102\n",
      "Epoch 70/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0485 - acc: 0.0023 - val_loss: 0.0820 - val_acc: 0.0102\n",
      "Epoch 71/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0794 - val_acc: 0.0102\n",
      "Epoch 72/200\n",
      "1750/1750 [==============================] - 0s 35us/step - loss: 0.0484 - acc: 0.0023 - val_loss: 0.0798 - val_acc: 0.0102\n",
      "Epoch 73/200\n",
      "1750/1750 [==============================] - 0s 34us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0810 - val_acc: 0.0102\n",
      "Epoch 74/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0485 - acc: 0.0023 - val_loss: 0.0784 - val_acc: 0.0102\n",
      "Epoch 75/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0486 - acc: 0.0023 - val_loss: 0.0805 - val_acc: 0.0102\n",
      "Epoch 76/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0484 - acc: 0.0023 - val_loss: 0.0805 - val_acc: 0.0102\n",
      "Epoch 77/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0486 - acc: 0.0023 - val_loss: 0.0799 - val_acc: 0.0102\n",
      "Epoch 78/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0484 - acc: 0.0023 - val_loss: 0.0806 - val_acc: 0.0102\n",
      "Epoch 79/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0485 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 80/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0485 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 81/200\n",
      "1750/1750 [==============================] - 0s 39us/step - loss: 0.0483 - acc: 0.0023 - val_loss: 0.0815 - val_acc: 0.0102\n",
      "Epoch 82/200\n",
      "1750/1750 [==============================] - 0s 40us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0789 - val_acc: 0.0102\n",
      "Epoch 83/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0483 - acc: 0.0023 - val_loss: 0.0784 - val_acc: 0.0102\n",
      "Epoch 84/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0481 - acc: 0.0023 - val_loss: 0.0798 - val_acc: 0.0102\n",
      "Epoch 85/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0480 - acc: 0.0023 - val_loss: 0.0786 - val_acc: 0.0102\n",
      "Epoch 86/200\n",
      "1750/1750 [==============================] - 0s 34us/step - loss: 0.0485 - acc: 0.0023 - val_loss: 0.0811 - val_acc: 0.0102\n",
      "Epoch 87/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0484 - acc: 0.0023 - val_loss: 0.0820 - val_acc: 0.0102\n",
      "Epoch 88/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0482 - acc: 0.0023 - val_loss: 0.0802 - val_acc: 0.0102\n",
      "Epoch 89/200\n",
      "1750/1750 [==============================] - 0s 32us/step - loss: 0.0484 - acc: 0.0023 - val_loss: 0.0804 - val_acc: 0.0102\n",
      "Epoch 90/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0484 - acc: 0.0023 - val_loss: 0.0774 - val_acc: 0.0102\n",
      "Epoch 91/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0483 - acc: 0.0023 - val_loss: 0.0793 - val_acc: 0.0102\n",
      "Epoch 92/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0481 - acc: 0.0023 - val_loss: 0.0809 - val_acc: 0.0102\n",
      "Epoch 93/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0484 - acc: 0.0023 - val_loss: 0.0800 - val_acc: 0.0102\n",
      "Epoch 94/200\n",
      "1750/1750 [==============================] - 0s 36us/step - loss: 0.0481 - acc: 0.0023 - val_loss: 0.0802 - val_acc: 0.0102\n",
      "Epoch 95/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0480 - acc: 0.0023 - val_loss: 0.0835 - val_acc: 0.0102\n",
      "Epoch 96/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0483 - acc: 0.0023 - val_loss: 0.0802 - val_acc: 0.0102\n",
      "Epoch 97/200\n",
      "1750/1750 [==============================] - 0s 34us/step - loss: 0.0480 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 98/200\n",
      "1750/1750 [==============================] - 0s 37us/step - loss: 0.0482 - acc: 0.0023 - val_loss: 0.0791 - val_acc: 0.0102\n",
      "Epoch 99/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0481 - acc: 0.0023 - val_loss: 0.0799 - val_acc: 0.0102\n",
      "Epoch 100/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0482 - acc: 0.0023 - val_loss: 0.0796 - val_acc: 0.0102\n",
      "Epoch 101/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0480 - acc: 0.0023 - val_loss: 0.0824 - val_acc: 0.0102\n",
      "Epoch 102/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0481 - acc: 0.0023 - val_loss: 0.0811 - val_acc: 0.0102\n",
      "Epoch 103/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0482 - acc: 0.0023 - val_loss: 0.0816 - val_acc: 0.0102\n",
      "Epoch 104/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0484 - acc: 0.0023 - val_loss: 0.0790 - val_acc: 0.0102\n",
      "Epoch 105/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0482 - acc: 0.0023 - val_loss: 0.0810 - val_acc: 0.0102\n",
      "Epoch 106/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0481 - acc: 0.0023 - val_loss: 0.0820 - val_acc: 0.0102\n",
      "Epoch 107/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0479 - acc: 0.0023 - val_loss: 0.0790 - val_acc: 0.0102\n",
      "Epoch 108/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0479 - acc: 0.0023 - val_loss: 0.0786 - val_acc: 0.0102\n",
      "Epoch 109/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0482 - acc: 0.0023 - val_loss: 0.0791 - val_acc: 0.0102\n",
      "Epoch 110/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0478 - acc: 0.0023 - val_loss: 0.0814 - val_acc: 0.0102\n",
      "Epoch 111/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0478 - acc: 0.0023 - val_loss: 0.0813 - val_acc: 0.0102\n",
      "Epoch 112/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0481 - acc: 0.0023 - val_loss: 0.0793 - val_acc: 0.0102\n",
      "Epoch 113/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0478 - acc: 0.0023 - val_loss: 0.0792 - val_acc: 0.0102\n",
      "Epoch 114/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0479 - acc: 0.0023 - val_loss: 0.0797 - val_acc: 0.0102\n",
      "Epoch 115/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0479 - acc: 0.0023 - val_loss: 0.0793 - val_acc: 0.0102\n",
      "Epoch 116/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0478 - acc: 0.0023 - val_loss: 0.0788 - val_acc: 0.0102\n",
      "Epoch 117/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0478 - acc: 0.0023 - val_loss: 0.0818 - val_acc: 0.0102\n",
      "Epoch 118/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0479 - acc: 0.0023 - val_loss: 0.0804 - val_acc: 0.0102\n",
      "Epoch 119/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0478 - acc: 0.0023 - val_loss: 0.0821 - val_acc: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0479 - acc: 0.0023 - val_loss: 0.0790 - val_acc: 0.0102\n",
      "Epoch 121/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0479 - acc: 0.0023 - val_loss: 0.0799 - val_acc: 0.0102\n",
      "Epoch 122/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0476 - acc: 0.0023 - val_loss: 0.0843 - val_acc: 0.0102\n",
      "Epoch 123/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0477 - acc: 0.0023 - val_loss: 0.0820 - val_acc: 0.0102\n",
      "Epoch 124/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0476 - acc: 0.0023 - val_loss: 0.0815 - val_acc: 0.0102\n",
      "Epoch 125/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0476 - acc: 0.0023 - val_loss: 0.0822 - val_acc: 0.0102\n",
      "Epoch 126/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0483 - acc: 0.0023 - val_loss: 0.0808 - val_acc: 0.0102\n",
      "Epoch 127/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0479 - acc: 0.0023 - val_loss: 0.0808 - val_acc: 0.0102\n",
      "Epoch 128/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0479 - acc: 0.0023 - val_loss: 0.0816 - val_acc: 0.0102\n",
      "Epoch 129/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0477 - acc: 0.0023 - val_loss: 0.0800 - val_acc: 0.0102\n",
      "Epoch 130/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0476 - acc: 0.0023 - val_loss: 0.0812 - val_acc: 0.0102\n",
      "Epoch 131/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0476 - acc: 0.0023 - val_loss: 0.0790 - val_acc: 0.0102\n",
      "Epoch 132/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0476 - acc: 0.0023 - val_loss: 0.0813 - val_acc: 0.0102\n",
      "Epoch 133/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0477 - acc: 0.0023 - val_loss: 0.0801 - val_acc: 0.0102\n",
      "Epoch 134/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0478 - acc: 0.0023 - val_loss: 0.0795 - val_acc: 0.0102\n",
      "Epoch 135/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0478 - acc: 0.0023 - val_loss: 0.0828 - val_acc: 0.0102\n",
      "Epoch 136/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0475 - acc: 0.0023 - val_loss: 0.0811 - val_acc: 0.0102\n",
      "Epoch 137/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0475 - acc: 0.0023 - val_loss: 0.0808 - val_acc: 0.0102\n",
      "Epoch 138/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0479 - acc: 0.0023 - val_loss: 0.0826 - val_acc: 0.0102\n",
      "Epoch 139/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0475 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 140/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0475 - acc: 0.0023 - val_loss: 0.0810 - val_acc: 0.0102\n",
      "Epoch 141/200\n",
      "1750/1750 [==============================] - 0s 35us/step - loss: 0.0477 - acc: 0.0023 - val_loss: 0.0814 - val_acc: 0.0102\n",
      "Epoch 142/200\n",
      "1750/1750 [==============================] - 0s 34us/step - loss: 0.0478 - acc: 0.0023 - val_loss: 0.0802 - val_acc: 0.0102\n",
      "Epoch 143/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0479 - acc: 0.0023 - val_loss: 0.0814 - val_acc: 0.0102\n",
      "Epoch 144/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0477 - acc: 0.0023 - val_loss: 0.0846 - val_acc: 0.0051\n",
      "Epoch 145/200\n",
      "1750/1750 [==============================] - 0s 34us/step - loss: 0.0478 - acc: 0.0017 - val_loss: 0.0803 - val_acc: 0.0102\n",
      "Epoch 146/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0475 - acc: 0.0023 - val_loss: 0.0792 - val_acc: 0.0102\n",
      "Epoch 147/200\n",
      "1750/1750 [==============================] - 0s 36us/step - loss: 0.0475 - acc: 0.0023 - val_loss: 0.0809 - val_acc: 0.0102\n",
      "Epoch 148/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0476 - acc: 0.0023 - val_loss: 0.0790 - val_acc: 0.0102\n",
      "Epoch 149/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0476 - acc: 0.0023 - val_loss: 0.0816 - val_acc: 0.0102\n",
      "Epoch 150/200\n",
      "1750/1750 [==============================] - 0s 37us/step - loss: 0.0474 - acc: 0.0023 - val_loss: 0.0828 - val_acc: 0.0102\n",
      "Epoch 151/200\n",
      "1750/1750 [==============================] - 0s 32us/step - loss: 0.0473 - acc: 0.0023 - val_loss: 0.0797 - val_acc: 0.0102\n",
      "Epoch 152/200\n",
      "1750/1750 [==============================] - 0s 35us/step - loss: 0.0476 - acc: 0.0023 - val_loss: 0.0835 - val_acc: 0.0102\n",
      "Epoch 153/200\n",
      "1750/1750 [==============================] - 0s 37us/step - loss: 0.0474 - acc: 0.0023 - val_loss: 0.0816 - val_acc: 0.0102\n",
      "Epoch 154/200\n",
      "1750/1750 [==============================] - 0s 35us/step - loss: 0.0476 - acc: 0.0023 - val_loss: 0.0849 - val_acc: 0.0102\n",
      "Epoch 155/200\n",
      "1750/1750 [==============================] - 0s 34us/step - loss: 0.0474 - acc: 0.0023 - val_loss: 0.0805 - val_acc: 0.0102\n",
      "Epoch 156/200\n",
      "1750/1750 [==============================] - 0s 37us/step - loss: 0.0476 - acc: 0.0023 - val_loss: 0.0803 - val_acc: 0.0102\n",
      "Epoch 157/200\n",
      "1750/1750 [==============================] - 0s 38us/step - loss: 0.0473 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 158/200\n",
      "1750/1750 [==============================] - 0s 34us/step - loss: 0.0475 - acc: 0.0023 - val_loss: 0.0821 - val_acc: 0.0102\n",
      "Epoch 159/200\n",
      "1750/1750 [==============================] - 0s 35us/step - loss: 0.0477 - acc: 0.0023 - val_loss: 0.0844 - val_acc: 0.0102\n",
      "Epoch 160/200\n",
      "1750/1750 [==============================] - 0s 40us/step - loss: 0.0478 - acc: 0.0023 - val_loss: 0.0801 - val_acc: 0.0102\n",
      "Epoch 161/200\n",
      "1750/1750 [==============================] - 0s 36us/step - loss: 0.0474 - acc: 0.0017 - val_loss: 0.0794 - val_acc: 0.0102\n",
      "Epoch 162/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0474 - acc: 0.0023 - val_loss: 0.0802 - val_acc: 0.0102\n",
      "Epoch 163/200\n",
      "1750/1750 [==============================] - 0s 32us/step - loss: 0.0474 - acc: 0.0023 - val_loss: 0.0813 - val_acc: 0.0102\n",
      "Epoch 164/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0475 - acc: 0.0023 - val_loss: 0.0803 - val_acc: 0.0102\n",
      "Epoch 165/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0473 - acc: 0.0023 - val_loss: 0.0808 - val_acc: 0.0102\n",
      "Epoch 166/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0475 - acc: 0.0023 - val_loss: 0.0837 - val_acc: 0.0102\n",
      "Epoch 167/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0478 - acc: 0.0023 - val_loss: 0.0797 - val_acc: 0.0102\n",
      "Epoch 168/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0474 - acc: 0.0023 - val_loss: 0.0819 - val_acc: 0.0102\n",
      "Epoch 169/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0471 - acc: 0.0023 - val_loss: 0.0824 - val_acc: 0.0102\n",
      "Epoch 170/200\n",
      "1750/1750 [==============================] - 0s 40us/step - loss: 0.0473 - acc: 0.0023 - val_loss: 0.0816 - val_acc: 0.0102\n",
      "Epoch 171/200\n",
      "1750/1750 [==============================] - 0s 37us/step - loss: 0.0476 - acc: 0.0023 - val_loss: 0.0819 - val_acc: 0.0102\n",
      "Epoch 172/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0472 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 173/200\n",
      "1750/1750 [==============================] - 0s 34us/step - loss: 0.0475 - acc: 0.0023 - val_loss: 0.0831 - val_acc: 0.0102\n",
      "Epoch 174/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0471 - acc: 0.0023 - val_loss: 0.0802 - val_acc: 0.0102\n",
      "Epoch 175/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0470 - acc: 0.0023 - val_loss: 0.0799 - val_acc: 0.0102\n",
      "Epoch 176/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0470 - acc: 0.0023 - val_loss: 0.0834 - val_acc: 0.0102\n",
      "Epoch 177/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0472 - acc: 0.0023 - val_loss: 0.0810 - val_acc: 0.0102\n",
      "Epoch 178/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0471 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 179/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0472 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 180/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0473 - acc: 0.0023 - val_loss: 0.0812 - val_acc: 0.0102\n",
      "Epoch 181/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0471 - acc: 0.0023 - val_loss: 0.0810 - val_acc: 0.0102\n",
      "Epoch 182/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0474 - acc: 0.0023 - val_loss: 0.0822 - val_acc: 0.0102\n",
      "Epoch 183/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0475 - acc: 0.0023 - val_loss: 0.0820 - val_acc: 0.0102\n",
      "Epoch 184/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0473 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 185/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0471 - acc: 0.0023 - val_loss: 0.0827 - val_acc: 0.0102\n",
      "Epoch 186/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0471 - acc: 0.0023 - val_loss: 0.0814 - val_acc: 0.0102\n",
      "Epoch 187/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0475 - acc: 0.0023 - val_loss: 0.0798 - val_acc: 0.0102\n",
      "Epoch 188/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0469 - acc: 0.0023 - val_loss: 0.0849 - val_acc: 0.0102\n",
      "Epoch 189/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0471 - acc: 0.0023 - val_loss: 0.0816 - val_acc: 0.0102\n",
      "Epoch 190/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0473 - acc: 0.0023 - val_loss: 0.0804 - val_acc: 0.0102\n",
      "Epoch 191/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0473 - acc: 0.0023 - val_loss: 0.0856 - val_acc: 0.0102\n",
      "Epoch 192/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0471 - acc: 0.0023 - val_loss: 0.0812 - val_acc: 0.0102\n",
      "Epoch 193/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0473 - acc: 0.0023 - val_loss: 0.0831 - val_acc: 0.0102\n",
      "Epoch 194/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0473 - acc: 0.0023 - val_loss: 0.0814 - val_acc: 0.0102\n",
      "Epoch 195/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0472 - acc: 0.0023 - val_loss: 0.0814 - val_acc: 0.0102\n",
      "Epoch 196/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0470 - acc: 0.0023 - val_loss: 0.0821 - val_acc: 0.0102\n",
      "Epoch 197/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0471 - acc: 0.0023 - val_loss: 0.0806 - val_acc: 0.0102\n",
      "Epoch 198/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0472 - acc: 0.0023 - val_loss: 0.0825 - val_acc: 0.0102\n",
      "Epoch 199/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0473 - acc: 0.0023 - val_loss: 0.0830 - val_acc: 0.0102\n",
      "Epoch 200/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0471 - acc: 0.0023 - val_loss: 0.0838 - val_acc: 0.0102\n",
      "\n",
      "> Entrenamiento realizado con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Configuración de la red neuronal\n",
    "model = Sequential()\n",
    "\n",
    "# Entrada / Capa oculta\n",
    "model.add(Dense(units=260, activation='relu', input_dim=10))\n",
    "\n",
    "# Capa de salida\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilado\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=0.001), metrics = ['accuracy'])\n",
    "\n",
    "# Entrenamiento\n",
    "datos_entrenamiento = model.fit(entrada_entrenamiento, salida_entrenamiento,  epochs=200, verbose=1, validation_data = (entrada_validacion, salida_validacion))\n",
    "\n",
    "print(\"\\n> Entrenamiento realizado con éxito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score del conjunto de validación es de: 0.0838.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSMhOWXzeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ec441fc828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gráfica\n",
    "plt.plot(datos_entrenamiento.history['loss'], label='loss')\n",
    "plt.plot(datos_entrenamiento.history['val_loss'], label='val_loss')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Puntuación\n",
    "score = model.evaluate(entrada_validacion, salida_validacion, verbose = 0)\n",
    "\n",
    "print(\"El score del conjunto de validación es de: %.4f.\" % (score[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación 2. Predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de supervivencia: \n",
      "\n",
      "- Tommen Baratheon: 7.07%\n",
      "- Daenerys Targaryen: 11.61%\n",
      "- Coldhands: 77.97%\n",
      "- Othell Yarwyck: 59.32%\n",
      "- Roland Crakehall (Kingsguard): 47.07%\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilidad de supervivencia: \\n\")\n",
    "\n",
    "Imprimir_Prediccion_Vida(datos_pre['name'], model.predict(entrada_pre) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorización de los pesos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos medios por entrada\n",
      "------------------------\n",
      " Característica    Peso \n",
      "------------------------\n",
      "- male: [-0.03003057]\n",
      "- book1: [-0.04740242]\n",
      "- book2: [-0.03694244]\n",
      "- book3: [-0.0261386]\n",
      "- book4: [ 0.00123119]\n",
      "- book5: [-0.03290815]\n",
      "- isMarried: [-0.02670936]\n",
      "- isNoble: [-0.00386382]\n",
      "- numDeadRelations: [-0.05936071]\n",
      "- isPopular: [ 0.0004857]\n"
     ]
    }
   ],
   "source": [
    "pesos_entrada = model.get_weights()[0]\n",
    "\n",
    "nombres_entrada = np.array(['male','book1','book2','book3',\n",
    "                            'book4','book5','isMarried','isNoble',\n",
    "                            'numDeadRelations','isPopular'])\n",
    "\n",
    "medias = np.array([ [np.average(pesos_entrada[0])], [np.average(pesos_entrada[1])], [np.average(pesos_entrada[2])],\n",
    "                    [np.average(pesos_entrada[3])], [np.average(pesos_entrada[4])], [np.average(pesos_entrada[5])],\n",
    "                    [np.average(pesos_entrada[6])], [np.average(pesos_entrada[7])], [np.average(pesos_entrada[8])],\n",
    "                    [np.average(pesos_entrada[9])]])\n",
    "\n",
    "print(\"Pesos medios por entrada\")\n",
    "print(\"------------------------\")\n",
    "print(\" Característica    Peso \")\n",
    "print(\"------------------------\")\n",
    "\n",
    "Imprimir_Medias_Pesos(nombres_entrada, medias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La característica isPopular es la que más tiende a 0, por lo que es la menos relevante para la red.\n",
    "\n",
    "#### La siguiente red predice también la probabilidad de supervivencia de los personajes pero sin la característica isPopular. Debería dar resultados similares pero no iguales, aunque afecte poco a la predicción, algo si que afecta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1750 samples, validate on 196 samples\n",
      "Epoch 1/200\n",
      "1750/1750 [==============================] - 0s 209us/step - loss: 0.0840 - acc: 0.0017 - val_loss: 0.0860 - val_acc: 0.0051\n",
      "Epoch 2/200\n",
      "1750/1750 [==============================] - 0s 34us/step - loss: 0.0622 - acc: 0.0011 - val_loss: 0.0960 - val_acc: 0.0051\n",
      "Epoch 3/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0584 - acc: 0.0017 - val_loss: 0.0921 - val_acc: 0.0051\n",
      "Epoch 4/200\n",
      "1750/1750 [==============================] - 0s 38us/step - loss: 0.0571 - acc: 0.0011 - val_loss: 0.0892 - val_acc: 0.0102\n",
      "Epoch 5/200\n",
      "1750/1750 [==============================] - 0s 36us/step - loss: 0.0563 - acc: 0.0017 - val_loss: 0.0911 - val_acc: 0.0102\n",
      "Epoch 6/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0554 - acc: 0.0017 - val_loss: 0.0864 - val_acc: 0.0102\n",
      "Epoch 7/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0551 - acc: 0.0017 - val_loss: 0.0895 - val_acc: 0.0102\n",
      "Epoch 8/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0549 - acc: 0.0017 - val_loss: 0.0848 - val_acc: 0.0102\n",
      "Epoch 9/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0543 - acc: 0.0023 - val_loss: 0.0850 - val_acc: 0.0102\n",
      "Epoch 10/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0540 - acc: 0.0017 - val_loss: 0.0863 - val_acc: 0.0102\n",
      "Epoch 11/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0535 - acc: 0.0023 - val_loss: 0.0863 - val_acc: 0.0102\n",
      "Epoch 12/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0532 - acc: 0.0023 - val_loss: 0.0832 - val_acc: 0.0102\n",
      "Epoch 13/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0531 - acc: 0.0023 - val_loss: 0.0846 - val_acc: 0.0102\n",
      "Epoch 14/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0530 - acc: 0.0023 - val_loss: 0.0818 - val_acc: 0.0102\n",
      "Epoch 15/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0526 - acc: 0.0023 - val_loss: 0.0822 - val_acc: 0.0102\n",
      "Epoch 16/200\n",
      "1750/1750 [==============================] - 0s 32us/step - loss: 0.0526 - acc: 0.0023 - val_loss: 0.0857 - val_acc: 0.0102\n",
      "Epoch 17/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0524 - acc: 0.0023 - val_loss: 0.0823 - val_acc: 0.0102\n",
      "Epoch 18/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0524 - acc: 0.0023 - val_loss: 0.0832 - val_acc: 0.0102\n",
      "Epoch 19/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0522 - acc: 0.0023 - val_loss: 0.0810 - val_acc: 0.0102\n",
      "Epoch 20/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0525 - acc: 0.0023 - val_loss: 0.0809 - val_acc: 0.0102\n",
      "Epoch 21/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0518 - acc: 0.0023 - val_loss: 0.0808 - val_acc: 0.0102\n",
      "Epoch 22/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0521 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 23/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0522 - acc: 0.0023 - val_loss: 0.0828 - val_acc: 0.0102\n",
      "Epoch 24/200\n",
      "1750/1750 [==============================] - 0s 39us/step - loss: 0.0520 - acc: 0.0023 - val_loss: 0.0803 - val_acc: 0.0102\n",
      "Epoch 25/200\n",
      "1750/1750 [==============================] - 0s 35us/step - loss: 0.0518 - acc: 0.0023 - val_loss: 0.0812 - val_acc: 0.0102\n",
      "Epoch 26/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0518 - acc: 0.0023 - val_loss: 0.0831 - val_acc: 0.0102\n",
      "Epoch 27/200\n",
      "1750/1750 [==============================] - 0s 32us/step - loss: 0.0515 - acc: 0.0023 - val_loss: 0.0811 - val_acc: 0.0102\n",
      "Epoch 28/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0515 - acc: 0.0023 - val_loss: 0.0835 - val_acc: 0.0102\n",
      "Epoch 29/200\n",
      "1750/1750 [==============================] - 0s 35us/step - loss: 0.0513 - acc: 0.0023 - val_loss: 0.0812 - val_acc: 0.0102\n",
      "Epoch 30/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0512 - acc: 0.0023 - val_loss: 0.0801 - val_acc: 0.0102\n",
      "Epoch 31/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0509 - acc: 0.0023 - val_loss: 0.0815 - val_acc: 0.0102\n",
      "Epoch 32/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0514 - acc: 0.0023 - val_loss: 0.0794 - val_acc: 0.0102\n",
      "Epoch 33/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0514 - acc: 0.0023 - val_loss: 0.0837 - val_acc: 0.0102\n",
      "Epoch 34/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0511 - acc: 0.0023 - val_loss: 0.0800 - val_acc: 0.0102\n",
      "Epoch 35/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0513 - acc: 0.0023 - val_loss: 0.0834 - val_acc: 0.0102\n",
      "Epoch 36/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0511 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 37/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0513 - acc: 0.0023 - val_loss: 0.0804 - val_acc: 0.0102\n",
      "Epoch 38/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0512 - acc: 0.0023 - val_loss: 0.0868 - val_acc: 0.0102\n",
      "Epoch 39/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0512 - acc: 0.0023 - val_loss: 0.0801 - val_acc: 0.0102\n",
      "Epoch 40/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0508 - acc: 0.0023 - val_loss: 0.0871 - val_acc: 0.0102\n",
      "Epoch 41/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0516 - acc: 0.0023 - val_loss: 0.0804 - val_acc: 0.0102\n",
      "Epoch 42/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0509 - acc: 0.0023 - val_loss: 0.0778 - val_acc: 0.0102\n",
      "Epoch 43/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0511 - acc: 0.0023 - val_loss: 0.0798 - val_acc: 0.0102\n",
      "Epoch 44/200\n",
      "1750/1750 [==============================] - 0s 35us/step - loss: 0.0505 - acc: 0.0023 - val_loss: 0.0809 - val_acc: 0.0102\n",
      "Epoch 45/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0508 - acc: 0.0023 - val_loss: 0.0819 - val_acc: 0.0102\n",
      "Epoch 46/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0510 - acc: 0.0023 - val_loss: 0.0788 - val_acc: 0.0102\n",
      "Epoch 47/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0506 - acc: 0.0023 - val_loss: 0.0800 - val_acc: 0.0102\n",
      "Epoch 48/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0506 - acc: 0.0023 - val_loss: 0.0800 - val_acc: 0.0102\n",
      "Epoch 49/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0505 - acc: 0.0023 - val_loss: 0.0772 - val_acc: 0.0102\n",
      "Epoch 50/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0506 - acc: 0.0023 - val_loss: 0.0811 - val_acc: 0.0102\n",
      "Epoch 51/200\n",
      "1750/1750 [==============================] - 0s 39us/step - loss: 0.0509 - acc: 0.0023 - val_loss: 0.0804 - val_acc: 0.0102\n",
      "Epoch 52/200\n",
      "1750/1750 [==============================] - 0s 35us/step - loss: 0.0502 - acc: 0.0023 - val_loss: 0.0834 - val_acc: 0.0102\n",
      "Epoch 53/200\n",
      "1750/1750 [==============================] - 0s 37us/step - loss: 0.0505 - acc: 0.0023 - val_loss: 0.0791 - val_acc: 0.0102\n",
      "Epoch 54/200\n",
      "1750/1750 [==============================] - 0s 34us/step - loss: 0.0506 - acc: 0.0023 - val_loss: 0.0818 - val_acc: 0.0102\n",
      "Epoch 55/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0505 - acc: 0.0023 - val_loss: 0.0798 - val_acc: 0.0102\n",
      "Epoch 56/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0502 - acc: 0.0023 - val_loss: 0.0786 - val_acc: 0.0102\n",
      "Epoch 57/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0505 - acc: 0.0023 - val_loss: 0.0775 - val_acc: 0.0102\n",
      "Epoch 58/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0501 - acc: 0.0023 - val_loss: 0.0818 - val_acc: 0.0102\n",
      "Epoch 59/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0505 - acc: 0.0023 - val_loss: 0.0793 - val_acc: 0.0102\n",
      "Epoch 60/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0500 - acc: 0.0023 - val_loss: 0.0816 - val_acc: 0.0102\n",
      "Epoch 61/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0504 - acc: 0.0023 - val_loss: 0.0809 - val_acc: 0.0102\n",
      "Epoch 62/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0502 - acc: 0.0023 - val_loss: 0.0821 - val_acc: 0.0102\n",
      "Epoch 63/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0502 - acc: 0.0023 - val_loss: 0.0817 - val_acc: 0.0102\n",
      "Epoch 64/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0507 - acc: 0.0023 - val_loss: 0.0815 - val_acc: 0.0102\n",
      "Epoch 65/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0502 - acc: 0.0023 - val_loss: 0.0793 - val_acc: 0.0102\n",
      "Epoch 66/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0503 - acc: 0.0023 - val_loss: 0.0798 - val_acc: 0.0102\n",
      "Epoch 67/200\n",
      "1750/1750 [==============================] - 0s 32us/step - loss: 0.0500 - acc: 0.0023 - val_loss: 0.0804 - val_acc: 0.0102\n",
      "Epoch 68/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0498 - acc: 0.0023 - val_loss: 0.0839 - val_acc: 0.0102\n",
      "Epoch 69/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0503 - acc: 0.0023 - val_loss: 0.0780 - val_acc: 0.0102\n",
      "Epoch 70/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0500 - acc: 0.0023 - val_loss: 0.0810 - val_acc: 0.0102\n",
      "Epoch 71/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0500 - acc: 0.0023 - val_loss: 0.0812 - val_acc: 0.0102\n",
      "Epoch 72/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0500 - acc: 0.0023 - val_loss: 0.0799 - val_acc: 0.0102\n",
      "Epoch 73/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0499 - acc: 0.0023 - val_loss: 0.0805 - val_acc: 0.0102\n",
      "Epoch 74/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0498 - acc: 0.0023 - val_loss: 0.0772 - val_acc: 0.0102\n",
      "Epoch 75/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0499 - acc: 0.0023 - val_loss: 0.0820 - val_acc: 0.0102\n",
      "Epoch 76/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0498 - acc: 0.0023 - val_loss: 0.0799 - val_acc: 0.0102\n",
      "Epoch 77/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0496 - acc: 0.0023 - val_loss: 0.0792 - val_acc: 0.0102\n",
      "Epoch 78/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0496 - acc: 0.0023 - val_loss: 0.0847 - val_acc: 0.0102\n",
      "Epoch 79/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0501 - acc: 0.0023 - val_loss: 0.0792 - val_acc: 0.0102\n",
      "Epoch 80/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0497 - acc: 0.0023 - val_loss: 0.0808 - val_acc: 0.0102\n",
      "Epoch 81/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0496 - acc: 0.0023 - val_loss: 0.0857 - val_acc: 0.0102\n",
      "Epoch 82/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0500 - acc: 0.0023 - val_loss: 0.0805 - val_acc: 0.0102\n",
      "Epoch 83/200\n",
      "1750/1750 [==============================] - 0s 26us/step - loss: 0.0495 - acc: 0.0023 - val_loss: 0.0806 - val_acc: 0.0102\n",
      "Epoch 84/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0497 - acc: 0.0023 - val_loss: 0.0791 - val_acc: 0.0102\n",
      "Epoch 85/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0495 - acc: 0.0023 - val_loss: 0.0810 - val_acc: 0.0102\n",
      "Epoch 86/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0500 - acc: 0.0023 - val_loss: 0.0797 - val_acc: 0.0102\n",
      "Epoch 87/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0495 - acc: 0.0023 - val_loss: 0.0848 - val_acc: 0.0102\n",
      "Epoch 88/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0498 - acc: 0.0023 - val_loss: 0.0796 - val_acc: 0.0102\n",
      "Epoch 89/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0494 - acc: 0.0023 - val_loss: 0.0815 - val_acc: 0.0102\n",
      "Epoch 90/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0495 - acc: 0.0023 - val_loss: 0.0799 - val_acc: 0.0102\n",
      "Epoch 91/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0497 - acc: 0.0023 - val_loss: 0.0819 - val_acc: 0.0102\n",
      "Epoch 92/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0495 - acc: 0.0023 - val_loss: 0.0799 - val_acc: 0.0102\n",
      "Epoch 93/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0494 - acc: 0.0023 - val_loss: 0.0793 - val_acc: 0.0102\n",
      "Epoch 94/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0496 - acc: 0.0023 - val_loss: 0.0828 - val_acc: 0.0102\n",
      "Epoch 95/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0498 - acc: 0.0023 - val_loss: 0.0852 - val_acc: 0.0102\n",
      "Epoch 96/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0506 - acc: 0.0023 - val_loss: 0.0775 - val_acc: 0.0102\n",
      "Epoch 97/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0497 - acc: 0.0023 - val_loss: 0.0793 - val_acc: 0.0102\n",
      "Epoch 98/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0493 - acc: 0.0023 - val_loss: 0.0791 - val_acc: 0.0102\n",
      "Epoch 99/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0495 - acc: 0.0023 - val_loss: 0.0808 - val_acc: 0.0102\n",
      "Epoch 100/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0493 - acc: 0.0023 - val_loss: 0.0782 - val_acc: 0.0102\n",
      "Epoch 101/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0494 - acc: 0.0023 - val_loss: 0.0778 - val_acc: 0.0102\n",
      "Epoch 102/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0495 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 103/200\n",
      "1750/1750 [==============================] - 0s 35us/step - loss: 0.0499 - acc: 0.0023 - val_loss: 0.0812 - val_acc: 0.0102\n",
      "Epoch 104/200\n",
      "1750/1750 [==============================] - 0s 36us/step - loss: 0.0498 - acc: 0.0023 - val_loss: 0.0841 - val_acc: 0.0102\n",
      "Epoch 105/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0492 - acc: 0.0023 - val_loss: 0.0797 - val_acc: 0.0102\n",
      "Epoch 106/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0493 - acc: 0.0023 - val_loss: 0.0822 - val_acc: 0.0102\n",
      "Epoch 107/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0493 - acc: 0.0023 - val_loss: 0.0810 - val_acc: 0.0102\n",
      "Epoch 108/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0493 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 109/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0492 - acc: 0.0023 - val_loss: 0.0797 - val_acc: 0.0102\n",
      "Epoch 110/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0492 - acc: 0.0023 - val_loss: 0.0803 - val_acc: 0.0102\n",
      "Epoch 111/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0493 - acc: 0.0023 - val_loss: 0.0791 - val_acc: 0.0102\n",
      "Epoch 112/200\n",
      "1750/1750 [==============================] - 0s 33us/step - loss: 0.0493 - acc: 0.0023 - val_loss: 0.0817 - val_acc: 0.0102\n",
      "Epoch 113/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0494 - acc: 0.0023 - val_loss: 0.0806 - val_acc: 0.0102\n",
      "Epoch 114/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0492 - acc: 0.0023 - val_loss: 0.0834 - val_acc: 0.0102\n",
      "Epoch 115/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0491 - acc: 0.0023 - val_loss: 0.0829 - val_acc: 0.0102\n",
      "Epoch 116/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0493 - acc: 0.0023 - val_loss: 0.0811 - val_acc: 0.0102\n",
      "Epoch 117/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0493 - acc: 0.0023 - val_loss: 0.0818 - val_acc: 0.0102\n",
      "Epoch 118/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0491 - acc: 0.0023 - val_loss: 0.0825 - val_acc: 0.0102\n",
      "Epoch 119/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0493 - acc: 0.0023 - val_loss: 0.0827 - val_acc: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0491 - acc: 0.0023 - val_loss: 0.0834 - val_acc: 0.0102\n",
      "Epoch 121/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0494 - acc: 0.0023 - val_loss: 0.0813 - val_acc: 0.0102\n",
      "Epoch 122/200\n",
      "1750/1750 [==============================] - 0s 35us/step - loss: 0.0492 - acc: 0.0023 - val_loss: 0.0838 - val_acc: 0.0102\n",
      "Epoch 123/200\n",
      "1750/1750 [==============================] - 0s 37us/step - loss: 0.0491 - acc: 0.0023 - val_loss: 0.0794 - val_acc: 0.0102\n",
      "Epoch 124/200\n",
      "1750/1750 [==============================] - 0s 35us/step - loss: 0.0490 - acc: 0.0023 - val_loss: 0.0801 - val_acc: 0.0102\n",
      "Epoch 125/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0490 - acc: 0.0023 - val_loss: 0.0801 - val_acc: 0.0102\n",
      "Epoch 126/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0490 - acc: 0.0023 - val_loss: 0.0812 - val_acc: 0.0102\n",
      "Epoch 127/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0797 - val_acc: 0.0102\n",
      "Epoch 128/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0492 - acc: 0.0023 - val_loss: 0.0855 - val_acc: 0.0102\n",
      "Epoch 129/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0495 - acc: 0.0023 - val_loss: 0.0802 - val_acc: 0.0102\n",
      "Epoch 130/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0495 - acc: 0.0023 - val_loss: 0.0833 - val_acc: 0.0102\n",
      "Epoch 131/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0491 - acc: 0.0023 - val_loss: 0.0831 - val_acc: 0.0102\n",
      "Epoch 132/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0494 - acc: 0.0023 - val_loss: 0.0784 - val_acc: 0.0102\n",
      "Epoch 133/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0493 - acc: 0.0023 - val_loss: 0.0832 - val_acc: 0.0102\n",
      "Epoch 134/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0492 - acc: 0.0023 - val_loss: 0.0803 - val_acc: 0.0102\n",
      "Epoch 135/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0491 - acc: 0.0023 - val_loss: 0.0805 - val_acc: 0.0102\n",
      "Epoch 136/200\n",
      "1750/1750 [==============================] - 0s 32us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 137/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0805 - val_acc: 0.0102\n",
      "Epoch 138/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0492 - acc: 0.0023 - val_loss: 0.0786 - val_acc: 0.0102\n",
      "Epoch 139/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0494 - acc: 0.0023 - val_loss: 0.0821 - val_acc: 0.0102\n",
      "Epoch 140/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0832 - val_acc: 0.0102\n",
      "Epoch 141/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0490 - acc: 0.0023 - val_loss: 0.0829 - val_acc: 0.0102\n",
      "Epoch 142/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0821 - val_acc: 0.0102\n",
      "Epoch 143/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0492 - acc: 0.0023 - val_loss: 0.0809 - val_acc: 0.0102\n",
      "Epoch 144/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0490 - acc: 0.0023 - val_loss: 0.0804 - val_acc: 0.0102\n",
      "Epoch 145/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0492 - acc: 0.0023 - val_loss: 0.0794 - val_acc: 0.0102\n",
      "Epoch 146/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0803 - val_acc: 0.0102\n",
      "Epoch 147/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0810 - val_acc: 0.0102\n",
      "Epoch 148/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0800 - val_acc: 0.0102\n",
      "Epoch 149/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0491 - acc: 0.0023 - val_loss: 0.0806 - val_acc: 0.0102\n",
      "Epoch 150/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0488 - acc: 0.0023 - val_loss: 0.0830 - val_acc: 0.0102\n",
      "Epoch 151/200\n",
      "1750/1750 [==============================] - 0s 32us/step - loss: 0.0488 - acc: 0.0023 - val_loss: 0.0802 - val_acc: 0.0102\n",
      "Epoch 152/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0488 - acc: 0.0023 - val_loss: 0.0805 - val_acc: 0.0102\n",
      "Epoch 153/200\n",
      "1750/1750 [==============================] - 0s 34us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0819 - val_acc: 0.0102\n",
      "Epoch 154/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0816 - val_acc: 0.0102\n",
      "Epoch 155/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0488 - acc: 0.0023 - val_loss: 0.0785 - val_acc: 0.0102\n",
      "Epoch 156/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0492 - acc: 0.0023 - val_loss: 0.0832 - val_acc: 0.0102\n",
      "Epoch 157/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0813 - val_acc: 0.0102\n",
      "Epoch 158/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0486 - acc: 0.0023 - val_loss: 0.0804 - val_acc: 0.0102\n",
      "Epoch 159/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0839 - val_acc: 0.0102\n",
      "Epoch 160/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0490 - acc: 0.0023 - val_loss: 0.0834 - val_acc: 0.0102\n",
      "Epoch 161/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0816 - val_acc: 0.0102\n",
      "Epoch 162/200\n",
      "1750/1750 [==============================] - 0s 39us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0808 - val_acc: 0.0102\n",
      "Epoch 163/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0822 - val_acc: 0.0102\n",
      "Epoch 164/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0486 - acc: 0.0023 - val_loss: 0.0821 - val_acc: 0.0102\n",
      "Epoch 165/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0799 - val_acc: 0.0102\n",
      "Epoch 166/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0806 - val_acc: 0.0102\n",
      "Epoch 167/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0806 - val_acc: 0.0102\n",
      "Epoch 168/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0485 - acc: 0.0023 - val_loss: 0.0805 - val_acc: 0.0102\n",
      "Epoch 169/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0805 - val_acc: 0.0102\n",
      "Epoch 170/200\n",
      "1750/1750 [==============================] - 0s 34us/step - loss: 0.0486 - acc: 0.0023 - val_loss: 0.0810 - val_acc: 0.0102\n",
      "Epoch 171/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0485 - acc: 0.0023 - val_loss: 0.0804 - val_acc: 0.0102\n",
      "Epoch 172/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0488 - acc: 0.0023 - val_loss: 0.0814 - val_acc: 0.0102\n",
      "Epoch 173/200\n",
      "1750/1750 [==============================] - 0s 34us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0822 - val_acc: 0.0102\n",
      "Epoch 174/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0486 - acc: 0.0023 - val_loss: 0.0818 - val_acc: 0.0102\n",
      "Epoch 175/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 176/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0486 - acc: 0.0023 - val_loss: 0.0801 - val_acc: 0.0102\n",
      "Epoch 177/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0488 - acc: 0.0023 - val_loss: 0.0831 - val_acc: 0.0102\n",
      "Epoch 178/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0488 - acc: 0.0023 - val_loss: 0.0823 - val_acc: 0.0102\n",
      "Epoch 179/200\n",
      "1750/1750 [==============================] - 0s 30us/step - loss: 0.0485 - acc: 0.0023 - val_loss: 0.0795 - val_acc: 0.0102\n",
      "Epoch 180/200\n",
      "1750/1750 [==============================] - 0s 38us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0791 - val_acc: 0.0102\n",
      "Epoch 181/200\n",
      "1750/1750 [==============================] - 0s 31us/step - loss: 0.0486 - acc: 0.0023 - val_loss: 0.0835 - val_acc: 0.0102\n",
      "Epoch 182/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0493 - acc: 0.0023 - val_loss: 0.0798 - val_acc: 0.0102\n",
      "Epoch 183/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0485 - acc: 0.0023 - val_loss: 0.0797 - val_acc: 0.0102\n",
      "Epoch 184/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0794 - val_acc: 0.0102\n",
      "Epoch 185/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0801 - val_acc: 0.0102\n",
      "Epoch 186/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0485 - acc: 0.0023 - val_loss: 0.0802 - val_acc: 0.0102\n",
      "Epoch 187/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0485 - acc: 0.0023 - val_loss: 0.0802 - val_acc: 0.0102\n",
      "Epoch 188/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0485 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 189/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0486 - acc: 0.0023 - val_loss: 0.0806 - val_acc: 0.0102\n",
      "Epoch 190/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0487 - acc: 0.0023 - val_loss: 0.0829 - val_acc: 0.0102\n",
      "Epoch 191/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0484 - acc: 0.0023 - val_loss: 0.0869 - val_acc: 0.0102\n",
      "Epoch 192/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0489 - acc: 0.0023 - val_loss: 0.0795 - val_acc: 0.0102\n",
      "Epoch 193/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0484 - acc: 0.0023 - val_loss: 0.0813 - val_acc: 0.0102\n",
      "Epoch 194/200\n",
      "1750/1750 [==============================] - 0s 29us/step - loss: 0.0486 - acc: 0.0023 - val_loss: 0.0807 - val_acc: 0.0102\n",
      "Epoch 195/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0486 - acc: 0.0023 - val_loss: 0.0820 - val_acc: 0.0102\n",
      "Epoch 196/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0483 - acc: 0.0023 - val_loss: 0.0813 - val_acc: 0.0102\n",
      "Epoch 197/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0486 - acc: 0.0023 - val_loss: 0.0819 - val_acc: 0.0102\n",
      "Epoch 198/200\n",
      "1750/1750 [==============================] - 0s 28us/step - loss: 0.0486 - acc: 0.0023 - val_loss: 0.0842 - val_acc: 0.0102\n",
      "Epoch 199/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0486 - acc: 0.0023 - val_loss: 0.0824 - val_acc: 0.0102\n",
      "Epoch 200/200\n",
      "1750/1750 [==============================] - 0s 27us/step - loss: 0.0486 - acc: 0.0023 - val_loss: 0.0795 - val_acc: 0.0102\n",
      "\n",
      "> Entrenamiento realizado con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Obtención del fichero de datos de entrenamiento\n",
    "datos = pd.read_csv('../Datos/got.csv')\n",
    "\n",
    "# Recolección de información de entrada para la red neuronal\n",
    "genero = datos.loc[:,'male']\n",
    "aparicion_libro_1 = datos.loc[:,'book1']\n",
    "aparicion_libro_2 = datos.loc[:,'book2']\n",
    "aparicion_libro_3 = datos.loc[:,'book3']\n",
    "aparicion_libro_4 = datos.loc[:,'book4']\n",
    "aparicion_libro_5 = datos.loc[:,'book5']\n",
    "casado = datos.loc[:,'isMarried']\n",
    "noble = datos.loc[:,'isNoble']\n",
    "numero_personas_cercanas_muertas = datos.loc[:,'numDeadRelations']\n",
    "    \n",
    "# Unión de la información de entrada\n",
    "entrada = np.array([[genero],[aparicion_libro_1],[aparicion_libro_2],[aparicion_libro_3],[aparicion_libro_4],\n",
    "        [aparicion_libro_5],[casado],[noble],[numero_personas_cercanas_muertas]])\n",
    "\n",
    "entrada = entrada.transpose().reshape(1946, 9)\n",
    "\n",
    "# Recolección de la salida esperada de la red neuronal\n",
    "salida_esperada = np.array(datos.loc[:,'alive'])\n",
    "\n",
    "# Conjunto entrenamiento\n",
    "entrada_entrenamiento = entrada[:1750,:]\n",
    "salida_entrenamiento = salida_esperada[:1750]\n",
    "\n",
    "# Conjunto validación\n",
    "entrada_validacion = entrada[1750:,:]\n",
    "salida_validacion = salida_esperada[1750:]\n",
    "\n",
    "# Configuración de la red neuronal\n",
    "model_sin_isPopular = Sequential()\n",
    "model_sin_isPopular.add(Dense(units=260, activation='relu', input_dim=9))\n",
    "model_sin_isPopular.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model_sin_isPopular.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=0.001), metrics = ['accuracy'])\n",
    "\n",
    "datos_entrenamiento_sin_isPopular= model_sin_isPopular.fit(entrada_entrenamiento, salida_entrenamiento, epochs=200, verbose=1, validation_data = (entrada_validacion, salida_validacion))\n",
    "\n",
    "print(\"\\n> Entrenamiento realizado con éxito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score del conjunto de validación es de: 0.0795.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niqIMIFT0FUVRBhD/H5+/7tthEOGQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ec44c2d048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(datos_entrenamiento_sin_isPopular.history['loss'], label='loss')\n",
    "plt.plot(datos_entrenamiento_sin_isPopular.history['val_loss'], label='val_loss')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "score = model_sin_isPopular.evaluate(entrada_validacion, salida_validacion, verbose = 0)\n",
    "\n",
    "print(\"El score del conjunto de validación es de: %.4f.\" % (score[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de supervivencia sin IsPopular: \n",
      "\n",
      "- Tommen Baratheon: 7.39%\n",
      "- Daenerys Targaryen: 16.12%\n",
      "- Coldhands: 75.17%\n",
      "- Othell Yarwyck: 52.06%\n",
      "- Roland Crakehall (Kingsguard): 42.43%\n"
     ]
    }
   ],
   "source": [
    "# Obtención del fichero de datos de entrenamiento\n",
    "datos_pre_sin_isPopular = pd.read_csv('../Datos/got_predicciones.csv')\n",
    "\n",
    "# Recolección de información de entrada para la red neuronal\n",
    "genero_sin_isPopular = datos_pre_sin_isPopular.loc[:,'male']\n",
    "aparicion_libro_1_sin_isPopular = datos_pre_sin_isPopular.loc[:,'book1']\n",
    "aparicion_libro_2_sin_isPopular = datos_pre_sin_isPopular.loc[:,'book2']\n",
    "aparicion_libro_3_sin_isPopular = datos_pre_sin_isPopular.loc[:,'book3']\n",
    "aparicion_libro_4_sin_isPopular = datos_pre_sin_isPopular.loc[:,'book4']\n",
    "aparicion_libro_5_sin_isPopular = datos_pre_sin_isPopular.loc[:,'book5']\n",
    "casado_sin_isPopular = datos_pre_sin_isPopular.loc[:,'isMarried']\n",
    "noble_sin_isPopular = datos_pre_sin_isPopular.loc[:,'isNoble']\n",
    "numero_personas_cercanas_muertas_sin_isPopular = datos_pre_sin_isPopular.loc[:,'numDeadRelations']\n",
    "    \n",
    "# Unión de la información de entrada\n",
    "entrada_pre_sin_isPopular = np.array([[genero_sin_isPopular],[aparicion_libro_1_sin_isPopular],[aparicion_libro_2_sin_isPopular],[aparicion_libro_3_sin_isPopular],[aparicion_libro_4_sin_isPopular],\n",
    "        [aparicion_libro_5_sin_isPopular],[casado_sin_isPopular],[noble_sin_isPopular],[numero_personas_cercanas_muertas_sin_isPopular]])\n",
    "\n",
    "entrada_pre_sin_isPopular = entrada_pre_sin_isPopular.transpose().reshape(5, 9)\n",
    "\n",
    "print(\"Probabilidad de supervivencia sin IsPopular: \\n\")\n",
    "\n",
    "Imprimir_Prediccion_Vida(datos_pre['name'], model_sin_isPopular.predict(entrada_pre_sin_isPopular) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora probamos a modificar las características más relevantes para demostrar que así lo son y forzar que otro personaje muera.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de supervivencia: \n",
      "\n",
      "- Tommen Baratheon: 7.07%\n",
      "- Daenerys Targaryen: 44.81%\n",
      "- Coldhands: 77.97%\n",
      "- Othell Yarwyck: 59.32%\n",
      "- Roland Crakehall (Kingsguard): 47.07%\n"
     ]
    }
   ],
   "source": [
    "# Obtención del fichero de datos de entrenamiento\n",
    "datos_pre = pd.read_csv('../Datos/got_predicciones_modificado.csv')\n",
    "\n",
    "# Recolección de información de entrada para la red neuronal\n",
    "genero = datos_pre.loc[:,'male']\n",
    "aparicion_libro_1 = datos_pre.loc[:,'book1']\n",
    "aparicion_libro_2 = datos_pre.loc[:,'book2']\n",
    "aparicion_libro_3 = datos_pre.loc[:,'book3']\n",
    "aparicion_libro_4 = datos_pre.loc[:,'book4']\n",
    "aparicion_libro_5 = datos_pre.loc[:,'book5']\n",
    "casado = datos_pre.loc[:,'isMarried']\n",
    "noble = datos_pre.loc[:,'isNoble']\n",
    "numero_personas_cercanas_muertas = datos_pre.loc[:,'numDeadRelations']\n",
    "popular = datos_pre.loc[:,'isPopular']\n",
    "    \n",
    "# Unión de la información de entrada\n",
    "entrada_pre = np.array([[genero],[aparicion_libro_1],[aparicion_libro_2],[aparicion_libro_3],[aparicion_libro_4],\n",
    "        [aparicion_libro_5],[casado],[noble],[numero_personas_cercanas_muertas],[popular]])\n",
    "\n",
    "entrada_pre = entrada_pre.transpose().reshape(5, 10)\n",
    "\n",
    "print(\"Probabilidad de supervivencia: \\n\")\n",
    "Imprimir_Prediccion_Vida(datos_pre['name'], model.predict(entrada_pre) * 100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
