{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# Aquí se importan las librerias que se van a utiliar\n",
    "\n",
    "%reset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model, np_utils\n",
    "import keras.optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para imprimir la supervivencia de los personajes\n",
    "def Imprimir_Prediccion_Vida(personajes, genero, edad, precio, probabilidad):\n",
    "    num_total = 0\n",
    "    num_mujeres = 0\n",
    "    num_niños = 0\n",
    "    num_primera = 0\n",
    "    num_hombres = 0\n",
    "    for i in range(0, personajes.shape[0]):\n",
    "        num_total = num_total+1\n",
    "        if (precio[i] >= 500):\n",
    "            num_primera = num_primera+1\n",
    "        if (edad[i] <= 15):\n",
    "            num_niños = num_niños+1\n",
    "        if (genero[i] == \"female\"):\n",
    "            num_mujeres = num_mujeres+1\n",
    "        if (genero[i] == \"male\"):\n",
    "            num_hombres = num_hombres+1\n",
    "        print(\"- \" + str(personajes[i]) + \": \" + str(round(probabilidad[i][0],2)) + \"%\")\n",
    "    print(\"Número total de datos: \", num_total)\n",
    "    print(\"Número de mujeres: \", num_mujeres)\n",
    "    print(\"Número de hombres: \", num_hombres)\n",
    "    print(\"Número de niños: \", num_niños)\n",
    "    print(\"Número pasajeros primera clase: \", num_primera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función imprimir datos antes de la predicción\n",
    "def Imprimir_Datos (pasajeros, genero, edad, precio):\n",
    "    num_total = 0\n",
    "    num_mujeres = 0\n",
    "    num_hombres = 0\n",
    "    num_niños = 0\n",
    "    num_primera = 0\n",
    "    for i in range(0, pasajeros.shape[0]):\n",
    "        num_total = num_total+1\n",
    "        if (precio[i] >= 500):\n",
    "            num_primera = num_primera+1\n",
    "        if (edad[i] <= 15):\n",
    "            num_niños = num_niños+1\n",
    "        if (genero[i] == \"female\"):\n",
    "            num_mujeres = num_mujeres+1\n",
    "        if (genero[i] == \"male\"):\n",
    "            num_hombres = num_hombres+1\n",
    "    print(\"Número total de datos: \", num_total)\n",
    "    print(\"Número de mujeres: \", num_mujeres)\n",
    "    print(\"Número de hombres: \", num_hombres)\n",
    "    print(\"Número de niños: \", num_niños)\n",
    "    print(\"Número pasajeros primera clase: \", num_primera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función imprimir la media de los pesos\n",
    "def Imprimir_Medias_Pesos(nombres, pesos):\n",
    "    for i in range(0, nombres.shape[0]):\n",
    "        print(\"- \" + str(nombres[i]) + \": \" + str(pesos[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recolección datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos en el dataset: \n",
      "Número total de datos:  891\n",
      "Número de mujeres:  314\n",
      "Número de hombres:  577\n",
      "Número de niños:  83\n",
      "Número pasajeros primera clase:  3\n"
     ]
    }
   ],
   "source": [
    "# Obtención del fichero de datos de entrenamiento y validación\n",
    "datos = pd.read_csv('../Datos/titanic.csv')\n",
    "\n",
    "# Recolección de información de entrada para la red neuronal (especificada en el enunciado)\n",
    "clase = datos.loc[:,'Pclass']\n",
    "genero = datos.loc[:,'Sex']\n",
    "edad = datos.loc[:,'Age']\n",
    "tarifa = datos.loc[:,'Fare']\n",
    "puerto = datos.loc[:,'Embarked']\n",
    "\n",
    "# Eliminamos las casillas donde no existe el dato de la edad\n",
    "# Hacemos el .roud() debido a que la media de la edad sale con muchos decimales\n",
    "\n",
    "edad = datos['Age'].fillna(datos['Age'].mean()).round()\n",
    "\n",
    "# Convertimos \"male\" en 0 y \"female\" en 1 para poder hacer el entrenamiento\n",
    "genero = genero.replace('male', 0)\n",
    "genero = genero.replace('female', 1)\n",
    "\n",
    "# Convertiomos los datos de los puertos según estos datos:\n",
    "# Q ==> 0\n",
    "# S ==> 1\n",
    "# C ==> 2\n",
    "puerto = puerto.replace('Q', 0)\n",
    "puerto = puerto.replace('S', 1)\n",
    "puerto = puerto.replace('C', 2)\n",
    "\n",
    "# Unión de la información de entrada\n",
    "entrada = np.array([[clase],[genero],[edad],[tarifa],[puerto]])\n",
    "\n",
    "# Cambiamos el tamaño de la matriz\n",
    "entrada = entrada.transpose().reshape(891, 5)\n",
    "\n",
    "# Recolección de la salida esperada de la red neuronal\n",
    "salida_esperada = np.array(datos.loc[:,'Survived'])\n",
    "\n",
    "# Conjunto entrenamiento\n",
    "entrada_entrenamiento = entrada[:802,:]\n",
    "salida_entrenamiento = salida_esperada[:802]\n",
    "\n",
    "# Conjunto validación\n",
    "entrada_validacion = entrada[802:,:]\n",
    "salida_validacion = salida_esperada[802:]\n",
    "\n",
    "print(\"Los datos en el dataset: \")\n",
    "Imprimir_Datos(datos['Name'], datos['Sex'], datos['Age'], datos['Fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recolección datos de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención del fichero de datos de entrenamiento\n",
    "datos_pre = pd.read_csv('../Datos/predict_titanic.csv')\n",
    "\n",
    "# Recolección de información de entrada para la red neuronal\n",
    "clase = datos_pre.loc[:,'Pclass']\n",
    "genero = datos_pre.loc[:,'Sex']\n",
    "edad = datos_pre.loc[:,'Age']\n",
    "tarifa = datos_pre.loc[:,'Fare']\n",
    "puerto = datos_pre.loc[:,'Embarked']\n",
    "    \n",
    "# Eliminamos las casillas donde no existe el dato de la edad\n",
    "edad = datos_pre['Age'].fillna(datos_pre['Age'].mean()).round()\n",
    "\n",
    "# Hacemos lo mismo con la tarifa\n",
    "tarifa = datos_pre['Fare'].fillna(datos_pre['Fare'].mean())\n",
    "\n",
    "# Convertimos \"male\" en 0 y \"female\" en 1 para poder hacer el entrenamiento\n",
    "genero = genero.replace('male', 0)\n",
    "genero = genero.replace('female', 1)\n",
    "\n",
    "# Convertiomos los datos de los puertos según estos datos:\n",
    "# Q ==> 0\n",
    "# S ==> 1\n",
    "# C ==> 2\n",
    "puerto = puerto.replace('Q', 0)\n",
    "puerto = puerto.replace('S', 1)\n",
    "puerto = puerto.replace('C', 2)\n",
    "\n",
    "# Unión de la información de entrada\n",
    "entrada_pre = np.array([[clase],[genero],[edad],[tarifa],[puerto]])\n",
    "\n",
    "# Cambiamos el tamaño\n",
    "entrada_pre = entrada_pre.transpose().reshape(418,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación 1. Entrenamiento Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 802 samples, validate on 89 samples\n",
      "Epoch 1/250\n",
      "802/802 [==============================] - 3s 3ms/step - loss: 0.2658 - acc: 0.6209 - val_loss: 0.1849 - val_acc: 0.7191\n",
      "Epoch 2/250\n",
      "802/802 [==============================] - 0s 162us/step - loss: 0.2068 - acc: 0.6920 - val_loss: 0.1936 - val_acc: 0.6742\n",
      "Epoch 3/250\n",
      "802/802 [==============================] - 0s 171us/step - loss: 0.1979 - acc: 0.6895 - val_loss: 0.1818 - val_acc: 0.7303\n",
      "Epoch 4/250\n",
      "802/802 [==============================] - 0s 167us/step - loss: 0.1874 - acc: 0.7332 - val_loss: 0.1787 - val_acc: 0.6517\n",
      "Epoch 5/250\n",
      "802/802 [==============================] - 0s 161us/step - loss: 0.1810 - acc: 0.7357 - val_loss: 0.1667 - val_acc: 0.7865\n",
      "Epoch 6/250\n",
      "802/802 [==============================] - 0s 171us/step - loss: 0.1872 - acc: 0.7257 - val_loss: 0.1591 - val_acc: 0.7528\n",
      "Epoch 7/250\n",
      "802/802 [==============================] - 0s 170us/step - loss: 0.1763 - acc: 0.7456 - val_loss: 0.1460 - val_acc: 0.7978\n",
      "Epoch 8/250\n",
      "802/802 [==============================] - 0s 172us/step - loss: 0.1668 - acc: 0.7594 - val_loss: 0.1499 - val_acc: 0.7865\n",
      "Epoch 9/250\n",
      "802/802 [==============================] - 0s 171us/step - loss: 0.1612 - acc: 0.7706 - val_loss: 0.1440 - val_acc: 0.7865\n",
      "Epoch 10/250\n",
      "802/802 [==============================] - 0s 173us/step - loss: 0.1559 - acc: 0.7918 - val_loss: 0.1439 - val_acc: 0.7865\n",
      "Epoch 11/250\n",
      "802/802 [==============================] - 0s 176us/step - loss: 0.1538 - acc: 0.7805 - val_loss: 0.1458 - val_acc: 0.7753\n",
      "Epoch 12/250\n",
      "802/802 [==============================] - 0s 182us/step - loss: 0.1503 - acc: 0.7818 - val_loss: 0.1404 - val_acc: 0.7865\n",
      "Epoch 13/250\n",
      "802/802 [==============================] - 0s 171us/step - loss: 0.1479 - acc: 0.7968 - val_loss: 0.1455 - val_acc: 0.8090\n",
      "Epoch 14/250\n",
      "802/802 [==============================] - 0s 168us/step - loss: 0.1515 - acc: 0.7818 - val_loss: 0.1422 - val_acc: 0.7753\n",
      "Epoch 15/250\n",
      "802/802 [==============================] - 0s 161us/step - loss: 0.1524 - acc: 0.7781 - val_loss: 0.1396 - val_acc: 0.8090\n",
      "Epoch 16/250\n",
      "802/802 [==============================] - 0s 138us/step - loss: 0.1710 - acc: 0.7519 - val_loss: 0.1631 - val_acc: 0.7640\n",
      "Epoch 17/250\n",
      "802/802 [==============================] - 0s 130us/step - loss: 0.1510 - acc: 0.7718 - val_loss: 0.1419 - val_acc: 0.8090\n",
      "Epoch 18/250\n",
      "802/802 [==============================] - 0s 129us/step - loss: 0.1534 - acc: 0.7756 - val_loss: 0.1490 - val_acc: 0.8202\n",
      "Epoch 19/250\n",
      "802/802 [==============================] - 0s 122us/step - loss: 0.1569 - acc: 0.7793 - val_loss: 0.1439 - val_acc: 0.7978\n",
      "Epoch 20/250\n",
      "802/802 [==============================] - 0s 122us/step - loss: 0.1506 - acc: 0.7843 - val_loss: 0.1348 - val_acc: 0.7865\n",
      "Epoch 21/250\n",
      "802/802 [==============================] - 0s 126us/step - loss: 0.1577 - acc: 0.7793 - val_loss: 0.1391 - val_acc: 0.7978\n",
      "Epoch 22/250\n",
      "802/802 [==============================] - 0s 127us/step - loss: 0.1462 - acc: 0.7805 - val_loss: 0.1456 - val_acc: 0.8090\n",
      "Epoch 23/250\n",
      "802/802 [==============================] - 0s 135us/step - loss: 0.1699 - acc: 0.7606 - val_loss: 0.1431 - val_acc: 0.8090\n",
      "Epoch 24/250\n",
      "802/802 [==============================] - 0s 127us/step - loss: 0.1537 - acc: 0.7880 - val_loss: 0.1411 - val_acc: 0.7865\n",
      "Epoch 25/250\n",
      "802/802 [==============================] - 0s 132us/step - loss: 0.1454 - acc: 0.7855 - val_loss: 0.1336 - val_acc: 0.7978\n",
      "Epoch 26/250\n",
      "802/802 [==============================] - 0s 137us/step - loss: 0.1482 - acc: 0.7968 - val_loss: 0.1389 - val_acc: 0.7865\n",
      "Epoch 27/250\n",
      "802/802 [==============================] - 0s 140us/step - loss: 0.1638 - acc: 0.7606 - val_loss: 0.1341 - val_acc: 0.7865\n",
      "Epoch 28/250\n",
      "802/802 [==============================] - 0s 138us/step - loss: 0.1503 - acc: 0.7855 - val_loss: 0.1367 - val_acc: 0.8202\n",
      "Epoch 29/250\n",
      "802/802 [==============================] - 0s 135us/step - loss: 0.1587 - acc: 0.7793 - val_loss: 0.1394 - val_acc: 0.7978\n",
      "Epoch 30/250\n",
      "802/802 [==============================] - 0s 137us/step - loss: 0.1671 - acc: 0.7643 - val_loss: 0.1403 - val_acc: 0.7865\n",
      "Epoch 31/250\n",
      "802/802 [==============================] - 0s 136us/step - loss: 0.1551 - acc: 0.7731 - val_loss: 0.1425 - val_acc: 0.7865\n",
      "Epoch 32/250\n",
      "802/802 [==============================] - 0s 140us/step - loss: 0.1558 - acc: 0.7781 - val_loss: 0.1347 - val_acc: 0.7978\n",
      "Epoch 33/250\n",
      "802/802 [==============================] - 0s 132us/step - loss: 0.1496 - acc: 0.7930 - val_loss: 0.1350 - val_acc: 0.7865\n",
      "Epoch 34/250\n",
      "802/802 [==============================] - 0s 132us/step - loss: 0.1472 - acc: 0.7855 - val_loss: 0.1356 - val_acc: 0.8202\n",
      "Epoch 35/250\n",
      "802/802 [==============================] - 0s 137us/step - loss: 0.1491 - acc: 0.7918 - val_loss: 0.1628 - val_acc: 0.7528\n",
      "Epoch 36/250\n",
      "802/802 [==============================] - 0s 142us/step - loss: 0.1528 - acc: 0.7743 - val_loss: 0.1322 - val_acc: 0.7865\n",
      "Epoch 37/250\n",
      "802/802 [==============================] - 0s 142us/step - loss: 0.1446 - acc: 0.7905 - val_loss: 0.1364 - val_acc: 0.8090\n",
      "Epoch 38/250\n",
      "802/802 [==============================] - 0s 137us/step - loss: 0.1630 - acc: 0.7805 - val_loss: 0.1372 - val_acc: 0.8202\n",
      "Epoch 39/250\n",
      "802/802 [==============================] - 0s 132us/step - loss: 0.1497 - acc: 0.8005 - val_loss: 0.1330 - val_acc: 0.8202\n",
      "Epoch 40/250\n",
      "802/802 [==============================] - 0s 132us/step - loss: 0.1501 - acc: 0.7918 - val_loss: 0.1359 - val_acc: 0.8090\n",
      "Epoch 41/250\n",
      "802/802 [==============================] - 0s 135us/step - loss: 0.1634 - acc: 0.7668 - val_loss: 0.1361 - val_acc: 0.7865\n",
      "Epoch 42/250\n",
      "802/802 [==============================] - 0s 134us/step - loss: 0.1519 - acc: 0.7905 - val_loss: 0.1326 - val_acc: 0.8090\n",
      "Epoch 43/250\n",
      "802/802 [==============================] - 0s 138us/step - loss: 0.1446 - acc: 0.7993 - val_loss: 0.1327 - val_acc: 0.7978\n",
      "Epoch 44/250\n",
      "802/802 [==============================] - 0s 135us/step - loss: 0.1424 - acc: 0.7980 - val_loss: 0.1323 - val_acc: 0.8090\n",
      "Epoch 45/250\n",
      "802/802 [==============================] - 0s 121us/step - loss: 0.1470 - acc: 0.7993 - val_loss: 0.1305 - val_acc: 0.8090\n",
      "Epoch 46/250\n",
      "802/802 [==============================] - 0s 137us/step - loss: 0.1467 - acc: 0.7943 - val_loss: 0.1298 - val_acc: 0.8090\n",
      "Epoch 47/250\n",
      "802/802 [==============================] - 0s 132us/step - loss: 0.1706 - acc: 0.7581 - val_loss: 0.1460 - val_acc: 0.8202\n",
      "Epoch 48/250\n",
      "802/802 [==============================] - 0s 130us/step - loss: 0.1633 - acc: 0.7731 - val_loss: 0.1387 - val_acc: 0.7865\n",
      "Epoch 49/250\n",
      "802/802 [==============================] - 0s 135us/step - loss: 0.1510 - acc: 0.7818 - val_loss: 0.1397 - val_acc: 0.8090\n",
      "Epoch 50/250\n",
      "802/802 [==============================] - 0s 127us/step - loss: 0.1467 - acc: 0.8017 - val_loss: 0.1296 - val_acc: 0.8202\n",
      "Epoch 51/250\n",
      "802/802 [==============================] - 0s 126us/step - loss: 0.1452 - acc: 0.8005 - val_loss: 0.1365 - val_acc: 0.8315\n",
      "Epoch 52/250\n",
      "802/802 [==============================] - 0s 124us/step - loss: 0.1473 - acc: 0.7855 - val_loss: 0.1292 - val_acc: 0.8315\n",
      "Epoch 53/250\n",
      "802/802 [==============================] - 0s 129us/step - loss: 0.1437 - acc: 0.7993 - val_loss: 0.1262 - val_acc: 0.8202\n",
      "Epoch 54/250\n",
      "802/802 [==============================] - 0s 119us/step - loss: 0.1459 - acc: 0.7993 - val_loss: 0.1392 - val_acc: 0.8202\n",
      "Epoch 55/250\n",
      "802/802 [==============================] - 0s 135us/step - loss: 0.1478 - acc: 0.7880 - val_loss: 0.1422 - val_acc: 0.8315\n",
      "Epoch 56/250\n",
      "802/802 [==============================] - 0s 137us/step - loss: 0.1533 - acc: 0.7818 - val_loss: 0.1337 - val_acc: 0.8090\n",
      "Epoch 57/250\n",
      "802/802 [==============================] - 0s 121us/step - loss: 0.1477 - acc: 0.8005 - val_loss: 0.1435 - val_acc: 0.8090\n",
      "Epoch 58/250\n",
      "802/802 [==============================] - 0s 129us/step - loss: 0.1583 - acc: 0.7830 - val_loss: 0.1300 - val_acc: 0.8090\n",
      "Epoch 59/250\n",
      "802/802 [==============================] - 0s 127us/step - loss: 0.1498 - acc: 0.8055 - val_loss: 0.1285 - val_acc: 0.8090\n",
      "Epoch 60/250\n",
      "802/802 [==============================] - 0s 127us/step - loss: 0.1466 - acc: 0.7905 - val_loss: 0.1290 - val_acc: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/250\n",
      "802/802 [==============================] - 0s 122us/step - loss: 0.1452 - acc: 0.8042 - val_loss: 0.1274 - val_acc: 0.8202\n",
      "Epoch 62/250\n",
      "802/802 [==============================] - 0s 126us/step - loss: 0.1476 - acc: 0.7955 - val_loss: 0.1423 - val_acc: 0.8202\n",
      "Epoch 63/250\n",
      "802/802 [==============================] - 0s 142us/step - loss: 0.1621 - acc: 0.7830 - val_loss: 0.1287 - val_acc: 0.8202\n",
      "Epoch 64/250\n",
      "802/802 [==============================] - 0s 122us/step - loss: 0.1508 - acc: 0.7993 - val_loss: 0.1364 - val_acc: 0.8202\n",
      "Epoch 65/250\n",
      "802/802 [==============================] - 0s 141us/step - loss: 0.1505 - acc: 0.7968 - val_loss: 0.1285 - val_acc: 0.8090\n",
      "Epoch 66/250\n",
      "802/802 [==============================] - 0s 141us/step - loss: 0.1418 - acc: 0.8017 - val_loss: 0.1256 - val_acc: 0.8202\n",
      "Epoch 67/250\n",
      "802/802 [==============================] - 0s 131us/step - loss: 0.1491 - acc: 0.7968 - val_loss: 0.1289 - val_acc: 0.8202\n",
      "Epoch 68/250\n",
      "802/802 [==============================] - 0s 137us/step - loss: 0.1410 - acc: 0.8080 - val_loss: 0.1322 - val_acc: 0.7978\n",
      "Epoch 69/250\n",
      "802/802 [==============================] - 0s 136us/step - loss: 0.1481 - acc: 0.8055 - val_loss: 0.1286 - val_acc: 0.8315\n",
      "Epoch 70/250\n",
      "802/802 [==============================] - 0s 138us/step - loss: 0.1397 - acc: 0.8142 - val_loss: 0.1280 - val_acc: 0.8202\n",
      "Epoch 71/250\n",
      "802/802 [==============================] - 0s 131us/step - loss: 0.1397 - acc: 0.8155 - val_loss: 0.1262 - val_acc: 0.8202\n",
      "Epoch 72/250\n",
      "802/802 [==============================] - 0s 138us/step - loss: 0.1407 - acc: 0.8080 - val_loss: 0.1229 - val_acc: 0.8427\n",
      "Epoch 73/250\n",
      "802/802 [==============================] - 0s 152us/step - loss: 0.1483 - acc: 0.7993 - val_loss: 0.1265 - val_acc: 0.8090\n",
      "Epoch 74/250\n",
      "802/802 [==============================] - 0s 152us/step - loss: 0.1409 - acc: 0.8130 - val_loss: 0.1281 - val_acc: 0.7978\n",
      "Epoch 75/250\n",
      "802/802 [==============================] - 0s 148us/step - loss: 0.1434 - acc: 0.7968 - val_loss: 0.1318 - val_acc: 0.8090\n",
      "Epoch 76/250\n",
      "802/802 [==============================] - 0s 130us/step - loss: 0.1610 - acc: 0.7756 - val_loss: 0.1252 - val_acc: 0.8090\n",
      "Epoch 77/250\n",
      "802/802 [==============================] - 0s 129us/step - loss: 0.1448 - acc: 0.7993 - val_loss: 0.1236 - val_acc: 0.8427\n",
      "Epoch 78/250\n",
      "802/802 [==============================] - 0s 127us/step - loss: 0.1386 - acc: 0.8067 - val_loss: 0.1323 - val_acc: 0.8090\n",
      "Epoch 79/250\n",
      "802/802 [==============================] - 0s 127us/step - loss: 0.1539 - acc: 0.7830 - val_loss: 0.1321 - val_acc: 0.8090\n",
      "Epoch 80/250\n",
      "802/802 [==============================] - 0s 126us/step - loss: 0.1441 - acc: 0.8042 - val_loss: 0.1279 - val_acc: 0.8315\n",
      "Epoch 81/250\n",
      "802/802 [==============================] - 0s 125us/step - loss: 0.1401 - acc: 0.8155 - val_loss: 0.1226 - val_acc: 0.8315\n",
      "Epoch 82/250\n",
      "802/802 [==============================] - 0s 125us/step - loss: 0.1496 - acc: 0.7918 - val_loss: 0.1246 - val_acc: 0.8202\n",
      "Epoch 83/250\n",
      "802/802 [==============================] - 0s 121us/step - loss: 0.1394 - acc: 0.8092 - val_loss: 0.1272 - val_acc: 0.8202\n",
      "Epoch 84/250\n",
      "802/802 [==============================] - 0s 109us/step - loss: 0.1420 - acc: 0.8092 - val_loss: 0.1274 - val_acc: 0.8090\n",
      "Epoch 85/250\n",
      "802/802 [==============================] - 0s 115us/step - loss: 0.1441 - acc: 0.8067 - val_loss: 0.1237 - val_acc: 0.8202\n",
      "Epoch 86/250\n",
      "802/802 [==============================] - 0s 112us/step - loss: 0.1547 - acc: 0.7880 - val_loss: 0.1281 - val_acc: 0.8090\n",
      "Epoch 87/250\n",
      "802/802 [==============================] - 0s 111us/step - loss: 0.1548 - acc: 0.7843 - val_loss: 0.1314 - val_acc: 0.7865\n",
      "Epoch 88/250\n",
      "802/802 [==============================] - 0s 105us/step - loss: 0.1397 - acc: 0.8067 - val_loss: 0.1317 - val_acc: 0.8202\n",
      "Epoch 89/250\n",
      "802/802 [==============================] - 0s 106us/step - loss: 0.1448 - acc: 0.8042 - val_loss: 0.1228 - val_acc: 0.8202\n",
      "Epoch 90/250\n",
      "802/802 [==============================] - 0s 104us/step - loss: 0.1398 - acc: 0.8067 - val_loss: 0.1304 - val_acc: 0.8090\n",
      "Epoch 91/250\n",
      "802/802 [==============================] - 0s 109us/step - loss: 0.1447 - acc: 0.7955 - val_loss: 0.1252 - val_acc: 0.8202\n",
      "Epoch 92/250\n",
      "802/802 [==============================] - 0s 110us/step - loss: 0.1360 - acc: 0.8192 - val_loss: 0.1271 - val_acc: 0.8090\n",
      "Epoch 93/250\n",
      "802/802 [==============================] - 0s 115us/step - loss: 0.1704 - acc: 0.7718 - val_loss: 0.1287 - val_acc: 0.8090\n",
      "Epoch 94/250\n",
      "802/802 [==============================] - 0s 121us/step - loss: 0.1535 - acc: 0.7943 - val_loss: 0.1315 - val_acc: 0.8090\n",
      "Epoch 95/250\n",
      "802/802 [==============================] - 0s 110us/step - loss: 0.1521 - acc: 0.7980 - val_loss: 0.1276 - val_acc: 0.8315\n",
      "Epoch 96/250\n",
      "802/802 [==============================] - 0s 95us/step - loss: 0.1538 - acc: 0.8005 - val_loss: 0.1282 - val_acc: 0.8090\n",
      "Epoch 97/250\n",
      "802/802 [==============================] - 0s 97us/step - loss: 0.1433 - acc: 0.8092 - val_loss: 0.1247 - val_acc: 0.8090\n",
      "Epoch 98/250\n",
      "802/802 [==============================] - 0s 99us/step - loss: 0.1444 - acc: 0.7980 - val_loss: 0.1216 - val_acc: 0.8202\n",
      "Epoch 99/250\n",
      "802/802 [==============================] - 0s 97us/step - loss: 0.1492 - acc: 0.7918 - val_loss: 0.1247 - val_acc: 0.8090\n",
      "Epoch 100/250\n",
      "802/802 [==============================] - 0s 97us/step - loss: 0.1400 - acc: 0.8204 - val_loss: 0.1311 - val_acc: 0.7978\n",
      "Epoch 101/250\n",
      "802/802 [==============================] - 0s 95us/step - loss: 0.1437 - acc: 0.8130 - val_loss: 0.1316 - val_acc: 0.8202\n",
      "Epoch 102/250\n",
      "802/802 [==============================] - 0s 105us/step - loss: 0.1410 - acc: 0.8092 - val_loss: 0.1228 - val_acc: 0.8315\n",
      "Epoch 103/250\n",
      "802/802 [==============================] - 0s 95us/step - loss: 0.1477 - acc: 0.7880 - val_loss: 0.1249 - val_acc: 0.8090\n",
      "Epoch 104/250\n",
      "802/802 [==============================] - 0s 99us/step - loss: 0.1459 - acc: 0.7980 - val_loss: 0.1226 - val_acc: 0.8315\n",
      "Epoch 105/250\n",
      "802/802 [==============================] - 0s 99us/step - loss: 0.1440 - acc: 0.8030 - val_loss: 0.1277 - val_acc: 0.8202\n",
      "Epoch 106/250\n",
      "802/802 [==============================] - 0s 101us/step - loss: 0.1476 - acc: 0.8105 - val_loss: 0.1241 - val_acc: 0.8202\n",
      "Epoch 107/250\n",
      "802/802 [==============================] - 0s 97us/step - loss: 0.1402 - acc: 0.8117 - val_loss: 0.1216 - val_acc: 0.8315\n",
      "Epoch 108/250\n",
      "802/802 [==============================] - 0s 99us/step - loss: 0.1417 - acc: 0.8055 - val_loss: 0.1249 - val_acc: 0.8090\n",
      "Epoch 109/250\n",
      "802/802 [==============================] - 0s 90us/step - loss: 0.1377 - acc: 0.8105 - val_loss: 0.1241 - val_acc: 0.8202\n",
      "Epoch 110/250\n",
      "802/802 [==============================] - 0s 92us/step - loss: 0.1381 - acc: 0.8042 - val_loss: 0.1220 - val_acc: 0.8315\n",
      "Epoch 111/250\n",
      "802/802 [==============================] - 0s 90us/step - loss: 0.1427 - acc: 0.8130 - val_loss: 0.1201 - val_acc: 0.8202\n",
      "Epoch 112/250\n",
      "802/802 [==============================] - 0s 105us/step - loss: 0.1391 - acc: 0.8105 - val_loss: 0.1223 - val_acc: 0.8090\n",
      "Epoch 113/250\n",
      "802/802 [==============================] - 0s 109us/step - loss: 0.1397 - acc: 0.8092 - val_loss: 0.1221 - val_acc: 0.8202\n",
      "Epoch 114/250\n",
      "802/802 [==============================] - 0s 100us/step - loss: 0.1456 - acc: 0.7955 - val_loss: 0.1201 - val_acc: 0.8202\n",
      "Epoch 115/250\n",
      "802/802 [==============================] - 0s 109us/step - loss: 0.1348 - acc: 0.8192 - val_loss: 0.1263 - val_acc: 0.8315\n",
      "Epoch 116/250\n",
      "802/802 [==============================] - 0s 105us/step - loss: 0.1431 - acc: 0.8105 - val_loss: 0.1197 - val_acc: 0.8315\n",
      "Epoch 117/250\n",
      "802/802 [==============================] - 0s 81us/step - loss: 0.1390 - acc: 0.8167 - val_loss: 0.1240 - val_acc: 0.8090\n",
      "Epoch 118/250\n",
      "802/802 [==============================] - 0s 82us/step - loss: 0.1492 - acc: 0.7868 - val_loss: 0.1454 - val_acc: 0.8090\n",
      "Epoch 119/250\n",
      "802/802 [==============================] - 0s 97us/step - loss: 0.1498 - acc: 0.8005 - val_loss: 0.1451 - val_acc: 0.7978\n",
      "Epoch 120/250\n",
      "802/802 [==============================] - 0s 94us/step - loss: 0.1417 - acc: 0.8055 - val_loss: 0.1250 - val_acc: 0.7978\n",
      "Epoch 121/250\n",
      "802/802 [==============================] - 0s 91us/step - loss: 0.1386 - acc: 0.8142 - val_loss: 0.1224 - val_acc: 0.8202\n",
      "Epoch 122/250\n",
      "802/802 [==============================] - 0s 95us/step - loss: 0.1491 - acc: 0.8042 - val_loss: 0.1462 - val_acc: 0.8202\n",
      "Epoch 123/250\n",
      "802/802 [==============================] - 0s 94us/step - loss: 0.1511 - acc: 0.7930 - val_loss: 0.1256 - val_acc: 0.8090\n",
      "Epoch 124/250\n",
      "802/802 [==============================] - 0s 100us/step - loss: 0.1429 - acc: 0.8030 - val_loss: 0.1213 - val_acc: 0.8202\n",
      "Epoch 125/250\n",
      "802/802 [==============================] - 0s 104us/step - loss: 0.1562 - acc: 0.7993 - val_loss: 0.1494 - val_acc: 0.8202\n",
      "Epoch 126/250\n",
      "802/802 [==============================] - 0s 105us/step - loss: 0.1723 - acc: 0.7781 - val_loss: 0.1209 - val_acc: 0.8315\n",
      "Epoch 127/250\n",
      "802/802 [==============================] - 0s 101us/step - loss: 0.1351 - acc: 0.8180 - val_loss: 0.1207 - val_acc: 0.8202\n",
      "Epoch 128/250\n",
      "802/802 [==============================] - 0s 105us/step - loss: 0.1473 - acc: 0.7980 - val_loss: 0.1243 - val_acc: 0.8090\n",
      "Epoch 129/250\n",
      "802/802 [==============================] - 0s 90us/step - loss: 0.1369 - acc: 0.8130 - val_loss: 0.1191 - val_acc: 0.8202\n",
      "Epoch 130/250\n",
      "802/802 [==============================] - 0s 97us/step - loss: 0.1351 - acc: 0.8117 - val_loss: 0.1196 - val_acc: 0.8090\n",
      "Epoch 131/250\n",
      "802/802 [==============================] - 0s 96us/step - loss: 0.1348 - acc: 0.8167 - val_loss: 0.1220 - val_acc: 0.8202\n",
      "Epoch 132/250\n",
      "802/802 [==============================] - 0s 102us/step - loss: 0.1514 - acc: 0.7955 - val_loss: 0.1247 - val_acc: 0.8202\n",
      "Epoch 133/250\n",
      "802/802 [==============================] - 0s 100us/step - loss: 0.1430 - acc: 0.8080 - val_loss: 0.1168 - val_acc: 0.8202\n",
      "Epoch 134/250\n",
      "802/802 [==============================] - 0s 100us/step - loss: 0.1457 - acc: 0.8067 - val_loss: 0.1301 - val_acc: 0.8202\n",
      "Epoch 135/250\n",
      "802/802 [==============================] - 0s 98us/step - loss: 0.1491 - acc: 0.7943 - val_loss: 0.1239 - val_acc: 0.8090\n",
      "Epoch 136/250\n",
      "802/802 [==============================] - 0s 99us/step - loss: 0.1432 - acc: 0.8092 - val_loss: 0.1273 - val_acc: 0.8202\n",
      "Epoch 137/250\n",
      "802/802 [==============================] - 0s 96us/step - loss: 0.1378 - acc: 0.8130 - val_loss: 0.1215 - val_acc: 0.8090\n",
      "Epoch 138/250\n",
      "802/802 [==============================] - 0s 99us/step - loss: 0.1520 - acc: 0.7793 - val_loss: 0.1271 - val_acc: 0.8090\n",
      "Epoch 139/250\n",
      "802/802 [==============================] - 0s 99us/step - loss: 0.1422 - acc: 0.8105 - val_loss: 0.1211 - val_acc: 0.8315\n",
      "Epoch 140/250\n",
      "802/802 [==============================] - 0s 94us/step - loss: 0.1369 - acc: 0.8180 - val_loss: 0.1486 - val_acc: 0.7865\n",
      "Epoch 141/250\n",
      "802/802 [==============================] - 0s 96us/step - loss: 0.1561 - acc: 0.7781 - val_loss: 0.1193 - val_acc: 0.8090\n",
      "Epoch 142/250\n",
      "802/802 [==============================] - 0s 95us/step - loss: 0.1365 - acc: 0.8192 - val_loss: 0.1178 - val_acc: 0.8202\n",
      "Epoch 143/250\n",
      "802/802 [==============================] - 0s 99us/step - loss: 0.1371 - acc: 0.8167 - val_loss: 0.1181 - val_acc: 0.8315\n",
      "Epoch 144/250\n",
      "802/802 [==============================] - 0s 100us/step - loss: 0.1396 - acc: 0.8105 - val_loss: 0.1186 - val_acc: 0.8427\n",
      "Epoch 145/250\n",
      "802/802 [==============================] - 0s 95us/step - loss: 0.1325 - acc: 0.8155 - val_loss: 0.1192 - val_acc: 0.8315\n",
      "Epoch 146/250\n",
      "802/802 [==============================] - 0s 92us/step - loss: 0.1392 - acc: 0.8105 - val_loss: 0.1233 - val_acc: 0.8427\n",
      "Epoch 147/250\n",
      "802/802 [==============================] - 0s 95us/step - loss: 0.1477 - acc: 0.8017 - val_loss: 0.1178 - val_acc: 0.8315\n",
      "Epoch 148/250\n",
      "802/802 [==============================] - 0s 106us/step - loss: 0.1421 - acc: 0.8055 - val_loss: 0.1228 - val_acc: 0.8202\n",
      "Epoch 149/250\n",
      "802/802 [==============================] - 0s 104us/step - loss: 0.1338 - acc: 0.8142 - val_loss: 0.1206 - val_acc: 0.8315\n",
      "Epoch 150/250\n",
      "802/802 [==============================] - 0s 92us/step - loss: 0.1324 - acc: 0.8155 - val_loss: 0.1192 - val_acc: 0.8315\n",
      "Epoch 151/250\n",
      "802/802 [==============================] - 0s 96us/step - loss: 0.1364 - acc: 0.8067 - val_loss: 0.1177 - val_acc: 0.8315\n",
      "Epoch 152/250\n",
      "802/802 [==============================] - 0s 87us/step - loss: 0.1424 - acc: 0.8092 - val_loss: 0.1184 - val_acc: 0.8315\n",
      "Epoch 153/250\n",
      "802/802 [==============================] - 0s 85us/step - loss: 0.1440 - acc: 0.8130 - val_loss: 0.1229 - val_acc: 0.8315\n",
      "Epoch 154/250\n",
      "802/802 [==============================] - 0s 87us/step - loss: 0.1319 - acc: 0.8229 - val_loss: 0.1170 - val_acc: 0.8427\n",
      "Epoch 155/250\n",
      "802/802 [==============================] - 0s 82us/step - loss: 0.1317 - acc: 0.8242 - val_loss: 0.1202 - val_acc: 0.8315\n",
      "Epoch 156/250\n",
      "802/802 [==============================] - 0s 86us/step - loss: 0.1387 - acc: 0.8117 - val_loss: 0.1198 - val_acc: 0.8427\n",
      "Epoch 157/250\n",
      "802/802 [==============================] - 0s 86us/step - loss: 0.1408 - acc: 0.8180 - val_loss: 0.1247 - val_acc: 0.8427\n",
      "Epoch 158/250\n",
      "802/802 [==============================] - 0s 81us/step - loss: 0.1569 - acc: 0.7868 - val_loss: 0.1271 - val_acc: 0.8315\n",
      "Epoch 159/250\n",
      "802/802 [==============================] - 0s 82us/step - loss: 0.1401 - acc: 0.8142 - val_loss: 0.1173 - val_acc: 0.8427\n",
      "Epoch 160/250\n",
      "802/802 [==============================] - 0s 85us/step - loss: 0.1739 - acc: 0.7768 - val_loss: 0.1197 - val_acc: 0.8427\n",
      "Epoch 161/250\n",
      "802/802 [==============================] - 0s 82us/step - loss: 0.1340 - acc: 0.8080 - val_loss: 0.1174 - val_acc: 0.8427\n",
      "Epoch 162/250\n",
      "802/802 [==============================] - 0s 89us/step - loss: 0.1346 - acc: 0.8167 - val_loss: 0.1221 - val_acc: 0.8427\n",
      "Epoch 163/250\n",
      "802/802 [==============================] - 0s 94us/step - loss: 0.1337 - acc: 0.8204 - val_loss: 0.1146 - val_acc: 0.8427\n",
      "Epoch 164/250\n",
      "802/802 [==============================] - 0s 95us/step - loss: 0.1361 - acc: 0.8180 - val_loss: 0.1165 - val_acc: 0.8315\n",
      "Epoch 165/250\n",
      "802/802 [==============================] - 0s 96us/step - loss: 0.1422 - acc: 0.8080 - val_loss: 0.1172 - val_acc: 0.8539\n",
      "Epoch 166/250\n",
      "802/802 [==============================] - 0s 94us/step - loss: 0.1335 - acc: 0.8092 - val_loss: 0.1119 - val_acc: 0.8539\n",
      "Epoch 167/250\n",
      "802/802 [==============================] - 0s 95us/step - loss: 0.1365 - acc: 0.8192 - val_loss: 0.1187 - val_acc: 0.8427\n",
      "Epoch 168/250\n",
      "802/802 [==============================] - 0s 91us/step - loss: 0.1418 - acc: 0.8055 - val_loss: 0.1207 - val_acc: 0.8315\n",
      "Epoch 169/250\n",
      "802/802 [==============================] - 0s 97us/step - loss: 0.2119 - acc: 0.7269 - val_loss: 0.1605 - val_acc: 0.7978\n",
      "Epoch 170/250\n",
      "802/802 [==============================] - 0s 97us/step - loss: 0.1817 - acc: 0.7668 - val_loss: 0.1387 - val_acc: 0.7865\n",
      "Epoch 171/250\n",
      "802/802 [==============================] - 0s 91us/step - loss: 0.1548 - acc: 0.7905 - val_loss: 0.1242 - val_acc: 0.8315\n",
      "Epoch 172/250\n",
      "802/802 [==============================] - 0s 94us/step - loss: 0.1430 - acc: 0.8092 - val_loss: 0.1177 - val_acc: 0.8427\n",
      "Epoch 173/250\n",
      "802/802 [==============================] - 0s 92us/step - loss: 0.1353 - acc: 0.8204 - val_loss: 0.1141 - val_acc: 0.8539\n",
      "Epoch 174/250\n",
      "802/802 [==============================] - 0s 91us/step - loss: 0.1344 - acc: 0.8092 - val_loss: 0.1211 - val_acc: 0.8315\n",
      "Epoch 175/250\n",
      "802/802 [==============================] - 0s 95us/step - loss: 0.1384 - acc: 0.8142 - val_loss: 0.1258 - val_acc: 0.8652\n",
      "Epoch 176/250\n",
      "802/802 [==============================] - 0s 92us/step - loss: 0.1411 - acc: 0.7943 - val_loss: 0.1156 - val_acc: 0.8652\n",
      "Epoch 177/250\n",
      "802/802 [==============================] - 0s 86us/step - loss: 0.1680 - acc: 0.7756 - val_loss: 0.1169 - val_acc: 0.8539\n",
      "Epoch 178/250\n",
      "802/802 [==============================] - 0s 94us/step - loss: 0.1381 - acc: 0.8217 - val_loss: 0.1194 - val_acc: 0.8427\n",
      "Epoch 179/250\n",
      "802/802 [==============================] - 0s 100us/step - loss: 0.1297 - acc: 0.8242 - val_loss: 0.1196 - val_acc: 0.8315\n",
      "Epoch 180/250\n",
      "802/802 [==============================] - 0s 100us/step - loss: 0.1303 - acc: 0.8204 - val_loss: 0.1163 - val_acc: 0.8539\n",
      "Epoch 181/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 94us/step - loss: 0.1292 - acc: 0.8204 - val_loss: 0.1209 - val_acc: 0.8315\n",
      "Epoch 182/250\n",
      "802/802 [==============================] - 0s 87us/step - loss: 0.1321 - acc: 0.8092 - val_loss: 0.1141 - val_acc: 0.8427\n",
      "Epoch 183/250\n",
      "802/802 [==============================] - 0s 81us/step - loss: 0.1875 - acc: 0.7506 - val_loss: 0.1339 - val_acc: 0.8315\n",
      "Epoch 184/250\n",
      "802/802 [==============================] - 0s 80us/step - loss: 0.1605 - acc: 0.7905 - val_loss: 0.1246 - val_acc: 0.8315\n",
      "Epoch 185/250\n",
      "802/802 [==============================] - 0s 85us/step - loss: 0.1342 - acc: 0.8267 - val_loss: 0.1189 - val_acc: 0.8539\n",
      "Epoch 186/250\n",
      "802/802 [==============================] - 0s 82us/step - loss: 0.1780 - acc: 0.7668 - val_loss: 0.1124 - val_acc: 0.8427\n",
      "Epoch 187/250\n",
      "802/802 [==============================] - 0s 87us/step - loss: 0.1373 - acc: 0.8192 - val_loss: 0.1160 - val_acc: 0.8315\n",
      "Epoch 188/250\n",
      "802/802 [==============================] - 0s 90us/step - loss: 0.1400 - acc: 0.8130 - val_loss: 0.1161 - val_acc: 0.8427\n",
      "Epoch 189/250\n",
      "802/802 [==============================] - 0s 86us/step - loss: 0.1361 - acc: 0.8167 - val_loss: 0.1165 - val_acc: 0.8427\n",
      "Epoch 190/250\n",
      "802/802 [==============================] - 0s 90us/step - loss: 0.1314 - acc: 0.8204 - val_loss: 0.1162 - val_acc: 0.8427\n",
      "Epoch 191/250\n",
      "802/802 [==============================] - 0s 72us/step - loss: 0.1320 - acc: 0.8192 - val_loss: 0.1182 - val_acc: 0.8539\n",
      "Epoch 192/250\n",
      "802/802 [==============================] - 0s 81us/step - loss: 0.1389 - acc: 0.8055 - val_loss: 0.1154 - val_acc: 0.8539\n",
      "Epoch 193/250\n",
      "802/802 [==============================] - 0s 86us/step - loss: 0.1308 - acc: 0.8242 - val_loss: 0.1149 - val_acc: 0.8652\n",
      "Epoch 194/250\n",
      "802/802 [==============================] - 0s 84us/step - loss: 0.1360 - acc: 0.8117 - val_loss: 0.1199 - val_acc: 0.8315\n",
      "Epoch 195/250\n",
      "802/802 [==============================] - 0s 86us/step - loss: 0.1325 - acc: 0.8080 - val_loss: 0.1213 - val_acc: 0.8539\n",
      "Epoch 196/250\n",
      "802/802 [==============================] - 0s 87us/step - loss: 0.1318 - acc: 0.8267 - val_loss: 0.1215 - val_acc: 0.8427\n",
      "Epoch 197/250\n",
      "802/802 [==============================] - 0s 86us/step - loss: 0.1331 - acc: 0.8155 - val_loss: 0.1158 - val_acc: 0.8427\n",
      "Epoch 198/250\n",
      "802/802 [==============================] - 0s 90us/step - loss: 0.1383 - acc: 0.8080 - val_loss: 0.1159 - val_acc: 0.8427\n",
      "Epoch 199/250\n",
      "802/802 [==============================] - 0s 92us/step - loss: 0.1354 - acc: 0.8192 - val_loss: 0.1178 - val_acc: 0.8539\n",
      "Epoch 200/250\n",
      "802/802 [==============================] - 0s 97us/step - loss: 0.1480 - acc: 0.7968 - val_loss: 0.1125 - val_acc: 0.8539\n",
      "Epoch 201/250\n",
      "802/802 [==============================] - 0s 91us/step - loss: 0.1332 - acc: 0.8117 - val_loss: 0.1146 - val_acc: 0.8427\n",
      "Epoch 202/250\n",
      "802/802 [==============================] - 0s 94us/step - loss: 0.1307 - acc: 0.8180 - val_loss: 0.1148 - val_acc: 0.8539\n",
      "Epoch 203/250\n",
      "802/802 [==============================] - 0s 92us/step - loss: 0.1300 - acc: 0.8229 - val_loss: 0.1144 - val_acc: 0.8427\n",
      "Epoch 204/250\n",
      "802/802 [==============================] - 0s 94us/step - loss: 0.1330 - acc: 0.8217 - val_loss: 0.1181 - val_acc: 0.8539\n",
      "Epoch 205/250\n",
      "802/802 [==============================] - 0s 89us/step - loss: 0.1294 - acc: 0.8242 - val_loss: 0.1129 - val_acc: 0.8539\n",
      "Epoch 206/250\n",
      "802/802 [==============================] - 0s 94us/step - loss: 0.1283 - acc: 0.8192 - val_loss: 0.1170 - val_acc: 0.8315\n",
      "Epoch 207/250\n",
      "802/802 [==============================] - 0s 96us/step - loss: 0.1285 - acc: 0.8192 - val_loss: 0.1160 - val_acc: 0.8539\n",
      "Epoch 208/250\n",
      "802/802 [==============================] - 0s 96us/step - loss: 0.1341 - acc: 0.8092 - val_loss: 0.1158 - val_acc: 0.8315\n",
      "Epoch 209/250\n",
      "802/802 [==============================] - 0s 95us/step - loss: 0.1299 - acc: 0.8105 - val_loss: 0.1156 - val_acc: 0.8427\n",
      "Epoch 210/250\n",
      "802/802 [==============================] - 0s 89us/step - loss: 0.1304 - acc: 0.8204 - val_loss: 0.1158 - val_acc: 0.8315\n",
      "Epoch 211/250\n",
      "802/802 [==============================] - 0s 91us/step - loss: 0.1257 - acc: 0.8229 - val_loss: 0.1186 - val_acc: 0.8315\n",
      "Epoch 212/250\n",
      "802/802 [==============================] - 0s 96us/step - loss: 0.1338 - acc: 0.8279 - val_loss: 0.1134 - val_acc: 0.8315\n",
      "Epoch 213/250\n",
      "802/802 [==============================] - 0s 95us/step - loss: 0.1320 - acc: 0.8180 - val_loss: 0.1151 - val_acc: 0.8315\n",
      "Epoch 214/250\n",
      "802/802 [==============================] - 0s 99us/step - loss: 0.1345 - acc: 0.8192 - val_loss: 0.1182 - val_acc: 0.8202\n",
      "Epoch 215/250\n",
      "802/802 [==============================] - 0s 96us/step - loss: 0.1358 - acc: 0.8105 - val_loss: 0.1155 - val_acc: 0.8202\n",
      "Epoch 216/250\n",
      "802/802 [==============================] - 0s 96us/step - loss: 0.1411 - acc: 0.8080 - val_loss: 0.1179 - val_acc: 0.8315\n",
      "Epoch 217/250\n",
      "802/802 [==============================] - 0s 94us/step - loss: 0.1301 - acc: 0.8267 - val_loss: 0.1170 - val_acc: 0.8315\n",
      "Epoch 218/250\n",
      "802/802 [==============================] - 0s 96us/step - loss: 0.1413 - acc: 0.8017 - val_loss: 0.1225 - val_acc: 0.8652\n",
      "Epoch 219/250\n",
      "802/802 [==============================] - 0s 97us/step - loss: 0.1334 - acc: 0.8080 - val_loss: 0.1157 - val_acc: 0.8427\n",
      "Epoch 220/250\n",
      "802/802 [==============================] - 0s 97us/step - loss: 0.1306 - acc: 0.8117 - val_loss: 0.1177 - val_acc: 0.8315\n",
      "Epoch 221/250\n",
      "802/802 [==============================] - 0s 97us/step - loss: 0.1447 - acc: 0.8005 - val_loss: 0.1194 - val_acc: 0.8090\n",
      "Epoch 222/250\n",
      "802/802 [==============================] - 0s 91us/step - loss: 0.1339 - acc: 0.8229 - val_loss: 0.1149 - val_acc: 0.8315\n",
      "Epoch 223/250\n",
      "802/802 [==============================] - 0s 89us/step - loss: 0.1286 - acc: 0.8317 - val_loss: 0.1189 - val_acc: 0.8202\n",
      "Epoch 224/250\n",
      "802/802 [==============================] - 0s 90us/step - loss: 0.1350 - acc: 0.8167 - val_loss: 0.1163 - val_acc: 0.8315\n",
      "Epoch 225/250\n",
      "802/802 [==============================] - 0s 86us/step - loss: 0.1284 - acc: 0.8242 - val_loss: 0.1142 - val_acc: 0.8427\n",
      "Epoch 226/250\n",
      "802/802 [==============================] - 0s 92us/step - loss: 0.1330 - acc: 0.8204 - val_loss: 0.1173 - val_acc: 0.8652\n",
      "Epoch 227/250\n",
      "802/802 [==============================] - 0s 91us/step - loss: 0.1257 - acc: 0.8317 - val_loss: 0.1344 - val_acc: 0.8202\n",
      "Epoch 228/250\n",
      "802/802 [==============================] - 0s 91us/step - loss: 0.2461 - acc: 0.7145 - val_loss: 0.2088 - val_acc: 0.7528\n",
      "Epoch 229/250\n",
      "802/802 [==============================] - 0s 89us/step - loss: 0.2287 - acc: 0.7332 - val_loss: 0.2034 - val_acc: 0.7753\n",
      "Epoch 230/250\n",
      "802/802 [==============================] - 0s 87us/step - loss: 0.2138 - acc: 0.7581 - val_loss: 0.1950 - val_acc: 0.7640\n",
      "Epoch 231/250\n",
      "802/802 [==============================] - 0s 85us/step - loss: 0.2047 - acc: 0.7494 - val_loss: 0.1868 - val_acc: 0.7753\n",
      "Epoch 232/250\n",
      "802/802 [==============================] - 0s 86us/step - loss: 0.1936 - acc: 0.7681 - val_loss: 0.1807 - val_acc: 0.7528\n",
      "Epoch 233/250\n",
      "802/802 [==============================] - 0s 95us/step - loss: 0.1840 - acc: 0.7731 - val_loss: 0.1776 - val_acc: 0.7528\n",
      "Epoch 234/250\n",
      "802/802 [==============================] - 0s 89us/step - loss: 0.1831 - acc: 0.7743 - val_loss: 0.1761 - val_acc: 0.7416\n",
      "Epoch 235/250\n",
      "802/802 [==============================] - 0s 86us/step - loss: 0.1776 - acc: 0.7756 - val_loss: 0.1668 - val_acc: 0.7640\n",
      "Epoch 236/250\n",
      "802/802 [==============================] - 0s 86us/step - loss: 0.1716 - acc: 0.7893 - val_loss: 0.1528 - val_acc: 0.7753\n",
      "Epoch 237/250\n",
      "802/802 [==============================] - 0s 84us/step - loss: 0.1599 - acc: 0.7905 - val_loss: 0.1394 - val_acc: 0.7865\n",
      "Epoch 238/250\n",
      "802/802 [==============================] - 0s 90us/step - loss: 0.1504 - acc: 0.8030 - val_loss: 0.1238 - val_acc: 0.8090\n",
      "Epoch 239/250\n",
      "802/802 [==============================] - 0s 85us/step - loss: 0.1469 - acc: 0.8067 - val_loss: 0.1259 - val_acc: 0.8315\n",
      "Epoch 240/250\n",
      "802/802 [==============================] - 0s 96us/step - loss: 0.1623 - acc: 0.7943 - val_loss: 0.1213 - val_acc: 0.8090\n",
      "Epoch 241/250\n",
      "802/802 [==============================] - 0s 87us/step - loss: 0.1496 - acc: 0.8030 - val_loss: 0.1207 - val_acc: 0.8315\n",
      "Epoch 242/250\n",
      "802/802 [==============================] - 0s 91us/step - loss: 0.1427 - acc: 0.8117 - val_loss: 0.1159 - val_acc: 0.8315\n",
      "Epoch 243/250\n",
      "802/802 [==============================] - 0s 96us/step - loss: 0.1450 - acc: 0.8055 - val_loss: 0.1125 - val_acc: 0.8315\n",
      "Epoch 244/250\n",
      "802/802 [==============================] - 0s 95us/step - loss: 0.1446 - acc: 0.7993 - val_loss: 0.1136 - val_acc: 0.8315\n",
      "Epoch 245/250\n",
      "802/802 [==============================] - 0s 95us/step - loss: 0.1399 - acc: 0.8155 - val_loss: 0.1139 - val_acc: 0.8202\n",
      "Epoch 246/250\n",
      "802/802 [==============================] - 0s 97us/step - loss: 0.1391 - acc: 0.8142 - val_loss: 0.1127 - val_acc: 0.8202\n",
      "Epoch 247/250\n",
      "802/802 [==============================] - 0s 96us/step - loss: 0.1382 - acc: 0.8130 - val_loss: 0.1143 - val_acc: 0.8202\n",
      "Epoch 248/250\n",
      "802/802 [==============================] - 0s 97us/step - loss: 0.1461 - acc: 0.8042 - val_loss: 0.1172 - val_acc: 0.8539\n",
      "Epoch 249/250\n",
      "802/802 [==============================] - 0s 105us/step - loss: 0.1404 - acc: 0.8130 - val_loss: 0.1167 - val_acc: 0.8539\n",
      "Epoch 250/250\n",
      "802/802 [==============================] - 0s 105us/step - loss: 0.1411 - acc: 0.8192 - val_loss: 0.1134 - val_acc: 0.8315\n",
      "\n",
      "> Entrenamiento realizado con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Configuración de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(units=260, activation='relu', input_dim=5))   \n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=0.001), metrics = ['accuracy'])\n",
    "\n",
    "datos_entrenamiento = model.fit(entrada_entrenamiento, salida_entrenamiento,  epochs=250, verbose=1, validation_data = (entrada_validacion, salida_validacion))\n",
    "\n",
    "print(\"\\n> Entrenamiento realizado con éxito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score del conjunto de validación es de: 0.1134.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xeef08e5438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(datos_entrenamiento.history['loss'], label='loss')\n",
    "plt.plot(datos_entrenamiento.history['val_loss'], label='val_loss')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "score = model.evaluate(entrada_validacion, salida_validacion, verbose = 0)\n",
    "\n",
    "print(\"El score del conjunto de validación es de: %.4f.\" % (score[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación 2. Predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de supervivencia: \n",
      "\n",
      "- Kelly, Mr. James: 7.64%\n",
      "- Wilkes, Mrs. James (Ellen Needs): 41.0%\n",
      "- Myles, Mr. Thomas Francis: 6.25%\n",
      "- Wirz, Mr. Albert: 7.43%\n",
      "- Hirvonen, Mrs. Alexander (Helga E Lindqvist): 54.22%\n",
      "- Svensson, Mr. Johan Cervin: 22.23%\n",
      "- Connolly, Miss. Kate: 70.29%\n",
      "- Caldwell, Mr. Albert Francis: 7.21%\n",
      "- Abrahim, Mrs. Joseph (Sophie Halaut Easu): 64.45%\n",
      "- Davies, Mr. John Samuel: 2.37%\n",
      "- Ilieff, Mr. Ylio: 6.36%\n",
      "- Jones, Mr. Charles Cresson: 35.82%\n",
      "- Snyder, Mrs. John Pillsbury (Nelle Stevenson): 99.71%\n",
      "- Howard, Mr. Benjamin: 6.58%\n",
      "- Chaffee, Mrs. Herbert Fuller (Carrie Constance Toogood): 97.95%\n",
      "- del Carlo, Mrs. Sebastiano (Argenia Genovesi): 78.8%\n",
      "- Keane, Mr. Daniel: 16.56%\n",
      "- Assaf, Mr. Gerios: 27.52%\n",
      "- Ilmakangas, Miss. Ida Livija: 56.39%\n",
      "- Assaf Khalil, Mrs. Mariana (Miriam\")\": 32.67%\n",
      "- Rothschild, Mr. Martin: 22.34%\n",
      "- Olsen, Master. Artur Karl: 66.72%\n",
      "- Flegenheim, Mrs. Alfred (Antoinette): 98.44%\n",
      "- Williams, Mr. Richard Norris II: 47.95%\n",
      "- Ryerson, Mrs. Arthur Larned (Emily Maria Borie): 100.0%\n",
      "- Robins, Mr. Alexander A: 3.19%\n",
      "- Ostby, Miss. Helene Ragnhild: 98.91%\n",
      "- Daher, Mr. Shedid: 24.52%\n",
      "- Brady, Mr. John Bertram: 40.58%\n",
      "- Samaan, Mr. Elias: 3.28%\n",
      "- Louch, Mr. Charles Alexander: 8.58%\n",
      "- Jefferys, Mr. Clifford Thomas: 6.2%\n",
      "- Dean, Mrs. Bertram (Eva Georgetta Light): 53.9%\n",
      "- Johnston, Mrs. Andrew G (Elizabeth Lily\" Watson)\": 47.51%\n",
      "- Mock, Mr. Philipp Edmund: 23.57%\n",
      "- Katavelas, Mr. Vassilios (Catavelas Vassilios\")\": 38.58%\n",
      "- Roth, Miss. Sarah A: 54.31%\n",
      "- Cacic, Miss. Manda: 57.32%\n",
      "- Sap, Mr. Julius: 7.99%\n",
      "- Hee, Mr. Ling: 0.38%\n",
      "- Karun, Mr. Franz: 3.33%\n",
      "- Franklin, Mr. Thomas Parham: 38.41%\n",
      "- Goldsmith, Mr. Nathan: 4.87%\n",
      "- Corbett, Mrs. Walter H (Irene Colvin): 88.92%\n",
      "- Kimball, Mrs. Edwin Nelson Jr (Gertrude Parsons): 98.2%\n",
      "- Peltomaki, Mr. Nikolai Johannes: 9.14%\n",
      "- Chevre, Mr. Paul Romaine: 28.69%\n",
      "- Shaughnessy, Mr. Patrick: 8.25%\n",
      "- Bucknell, Mrs. William Robert (Emma Eliza Ward): 96.59%\n",
      "- Coutts, Mrs. William (Winnie Minnie\" Treanor)\": 53.99%\n",
      "- Smith, Mr. Lucien Philip: 30.37%\n",
      "- Pulbaum, Mr. Franz: 15.54%\n",
      "- Hocking, Miss. Ellen Nellie\"\": 84.89%\n",
      "- Fortune, Miss. Ethel Flora: 100.0%\n",
      "- Mangiavacchi, Mr. Serafino Emilio: 12.41%\n",
      "- Rice, Master. Albert: 1.55%\n",
      "- Cor, Mr. Bartol: 5.58%\n",
      "- Abelseth, Mr. Olaus Jorgensen: 9.36%\n",
      "- Davison, Mr. Thomas Henry: 4.58%\n",
      "- Chaudanson, Miss. Victorine: 100.0%\n",
      "- Dika, Mr. Mirko: 17.43%\n",
      "- McCrae, Mr. Arthur Gordon: 13.42%\n",
      "- Bjorklund, Mr. Ernst Herbert: 15.79%\n",
      "- Bradley, Miss. Bridget Delia: 70.12%\n",
      "- Ryerson, Master. John Borie: 100.0%\n",
      "- Corey, Mrs. Percy C (Mary Phyllis Elizabeth Miller): 89.79%\n",
      "- Burns, Miss. Mary Delia: 68.89%\n",
      "- Moore, Mr. Clarence Bloomfield: 34.69%\n",
      "- Tucker, Mr. Gilbert Milligan Jr: 29.64%\n",
      "- Fortune, Mrs. Mark (Mary McDougald): 100.0%\n",
      "- Mulvihill, Miss. Bertha E: 70.53%\n",
      "- Minkoff, Mr. Lazar: 11.78%\n",
      "- Nieminen, Miss. Manta Josefina: 55.01%\n",
      "- Ovies y Rodriguez, Mr. Servando: 29.03%\n",
      "- Geiger, Miss. Amalie: 100.0%\n",
      "- Keeping, Mr. Edwin: 100.0%\n",
      "- Miles, Mr. Frank: 6.3%\n",
      "- Cornell, Mrs. Robert Clifford (Malvina Helen Lamson): 98.11%\n",
      "- Aldworth, Mr. Charles Augustus: 14.25%\n",
      "- Doyle, Miss. Elizabeth: 70.53%\n",
      "- Boulos, Master. Akar: 85.37%\n",
      "- Straus, Mr. Isidor: 95.26%\n",
      "- Case, Mr. Howard Brown: 34.21%\n",
      "- Demetri, Mr. Marinko: 6.36%\n",
      "- Lamb, Mr. John Joseph: 18.93%\n",
      "- Khalil, Mr. Betros: 5.86%\n",
      "- Barry, Miss. Julia: 70.57%\n",
      "- Badman, Miss. Emily Louisa: 57.51%\n",
      "- O'Donoghue, Ms. Bridget: 70.31%\n",
      "- Wells, Master. Ralph Lester: 73.25%\n",
      "- Dyker, Mrs. Adolf Fredrik (Anna Elisabeth Judith Andersson): 52.24%\n",
      "- Pedersen, Mr. Olaf: 6.42%\n",
      "- Davidson, Mrs. Thornton (Orian Hays): 97.15%\n",
      "- Guest, Mr. Robert: 6.3%\n",
      "- Birnbaum, Mr. Jakob: 28.76%\n",
      "- Tenglin, Mr. Gunnar Isidor: 9.24%\n",
      "- Cavendish, Mrs. Tyrell William (Julia Florence Siegel): 98.1%\n",
      "- Makinen, Mr. Kalle Edvard: 6.8%\n",
      "- Braf, Miss. Elin Ester Maria: 58.01%\n",
      "- Nancarrow, Mr. William Henry: 5.82%\n",
      "- Stengel, Mrs. Charles Emil Henry (Annie May Morris): 96.91%\n",
      "- Weisz, Mr. Leopold: 8.71%\n",
      "- Foley, Mr. William: 8.25%\n",
      "- Johansson Palmquist, Mr. Oskar Leander: 8.61%\n",
      "- Thomas, Mrs. Alexander (Thamine Thelma\")\": 67.31%\n",
      "- Holthen, Mr. Johan Martin: 3.28%\n",
      "- Buckley, Mr. Daniel: 8.98%\n",
      "- Ryan, Mr. Edward: 8.25%\n",
      "- Willer, Mr. Aaron (Abi Weller\")\": 6.1%\n",
      "- Swane, Mr. George: 19.77%\n",
      "- Stanton, Mr. Samuel Ward: 8.14%\n",
      "- Shine, Miss. Ellen Natalia: 70.32%\n",
      "- Evans, Miss. Edith Corse: 97.73%\n",
      "- Buckley, Miss. Katherine: 69.19%\n",
      "- Straus, Mrs. Isidor (Rosalie Ida Blun): 99.99%\n",
      "- Chronopoulos, Mr. Demetrios: 18.96%\n",
      "- Thomas, Mr. John: 10.33%\n",
      "- Sandstrom, Miss. Beatrice Irene: 69.71%\n",
      "- Beattie, Mr. Thomson: 21.42%\n",
      "- Chapman, Mrs. John Henry (Sara Elizabeth Lawry): 87.58%\n",
      "- Watt, Miss. Bertha J: 83.62%\n",
      "- Kiernan, Mr. John: 8.25%\n",
      "- Schabert, Mrs. Paul (Emma Mock): 96.37%\n",
      "- Carver, Mr. Alfred John: 7.79%\n",
      "- Kennedy, Mr. John: 8.25%\n",
      "- Cribb, Miss. Laura Alice: 44.01%\n",
      "- Brobeck, Mr. Karl Rudolf: 11.24%\n",
      "- McCoy, Miss. Alicia: 63.25%\n",
      "- Bowenur, Mr. Solomon: 10.57%\n",
      "- Petersen, Mr. Marius: 9.7%\n",
      "- Spinner, Mr. Henry John: 5.96%\n",
      "- Gracie, Col. Archibald IV: 24.32%\n",
      "- Lefebre, Mrs. Frank (Frances): 44.83%\n",
      "- Thomas, Mr. Charles P: 10.33%\n",
      "- Dintcheff, Mr. Valtcho: 4.41%\n",
      "- Carlsson, Mr. Carl Robert: 9.86%\n",
      "- Zakarian, Mr. Mapriededer: 14.57%\n",
      "- Schmidt, Mr. August: 15.76%\n",
      "- Drapkin, Miss. Jennie: 57.75%\n",
      "- Goodwin, Mr. Charles Frederick: 0.85%\n",
      "- Goodwin, Miss. Jessie Allis: 34.4%\n",
      "- Daniels, Miss. Sarah: 99.99%\n",
      "- Ryerson, Mr. Arthur Larned: 99.96%\n",
      "- Beauchamp, Mr. Henry James: 8.92%\n",
      "- Lindeberg-Lind, Mr. Erik Gustaf (Mr Edward Lingrey\")\": 38.37%\n",
      "- Vander Planke, Mr. Julius: 4.2%\n",
      "- Hilliard, Mr. Herbert Henry: 23.4%\n",
      "- Davies, Mr. Evan: 10.96%\n",
      "- Crafton, Mr. John Bertram: 38.41%\n",
      "- Lahtinen, Rev. William: 9.35%\n",
      "- Earnshaw, Mrs. Boulton (Olive Potter): 99.73%\n",
      "- Matinoff, Mr. Nicola: 9.17%\n",
      "- Storey, Mr. Thomas: 1.8%\n",
      "- Klasen, Mrs. (Hulda Kristina Eugenia Lofqvist): 52.53%\n",
      "- Asplund, Master. Filip Oscar: 1.68%\n",
      "- Duquemin, Mr. Joseph: 10.14%\n",
      "- Bird, Miss. Ellen: 100.0%\n",
      "- Lundin, Miss. Olga Elida: 57.89%\n",
      "- Borebank, Mr. John James: 38.37%\n",
      "- Peacock, Mrs. Benjamin (Edith Nile): 54.93%\n",
      "- Smyth, Miss. Julia: 70.31%\n",
      "- Touma, Master. Georges Youssef: 80.26%\n",
      "- Wright, Miss. Marion: 89.71%\n",
      "- Pearce, Mr. Ernest: 6.79%\n",
      "- Peruschitz, Rev. Joseph Maria: 10.84%\n",
      "- Kink-Heilmann, Mrs. Anton (Luise Heilmann): 45.41%\n",
      "- Brandeis, Mr. Emil: 24.11%\n",
      "- Ford, Mr. Edward Watson: 1.07%\n",
      "- Cassebeer, Mrs. Henry Arthur Jr (Eleanor Genevieve Fosdick): 97.79%\n",
      "- Hellstrom, Miss. Hilda Maria: 57.04%\n",
      "- Lithman, Mr. Simon: 6.52%\n",
      "- Zakarian, Mr. Ortin: 12.79%\n",
      "- Dyker, Mr. Adolf Fredrik: 6.0%\n",
      "- Torfa, Mr. Assad: 9.69%\n",
      "- Asplund, Mr. Carl Oscar Vilhelm Gustafsson: 2.26%\n",
      "- Brown, Miss. Edith Eileen: 74.06%\n",
      "- Sincock, Miss. Maude: 73.85%\n",
      "- Stengel, Mr. Charles Emil Henry: 23.4%\n",
      "- Becker, Mrs. Allen Oliver (Nellie E Baumgardner): 84.83%\n",
      "- Compton, Mrs. Alexander Taylor (Mary Eliza Ingersoll): 96.49%\n",
      "- McCrie, Mr. James Matthew: 14.25%\n",
      "- Compton, Mr. Alexander Taylor Jr: 25.27%\n",
      "- Marvin, Mrs. Daniel Warner (Mary Graham Carmichael Farquarson): 98.91%\n",
      "- Lane, Mr. Patrick: 8.25%\n",
      "- Douglas, Mrs. Frederick Charles (Mary Helene Baxter): 100.0%\n",
      "- Maybery, Mr. Frank Hubert: 10.55%\n",
      "- Phillips, Miss. Alice Frances Louisa: 86.52%\n",
      "- Davies, Mr. Joseph: 17.12%\n",
      "- Sage, Miss. Ada: 13.58%\n",
      "- Veal, Mr. James: 11.11%\n",
      "- Angle, Mr. William A: 10.05%\n",
      "- Salomon, Mr. Abraham L: 38.85%\n",
      "- van Billiard, Master. Walter John: 14.52%\n",
      "- Lingane, Mr. John: 10.21%\n",
      "- Drew, Master. Marshall Brines: 13.59%\n",
      "- Karlsson, Mr. Julius Konrad Eugen: 5.86%\n",
      "- Spedden, Master. Robert Douglas: 100.0%\n",
      "- Nilsson, Miss. Berta Olivia: 57.83%\n",
      "- Baimbrigge, Mr. Charles Robert: 17.68%\n",
      "- Rasmussen, Mrs. (Lena Jacobsen Solvang): 54.3%\n",
      "- Murphy, Miss. Nora: 70.28%\n",
      "- Danbom, Master. Gilbert Sigvard Emanuel: 85.17%\n",
      "- Astor, Col. John Jacob: 99.97%\n",
      "- Quick, Miss. Winifred Vera: 78.11%\n",
      "- Andrew, Mr. Frank Thomas: 16.65%\n",
      "- Omont, Mr. Alfred Fernand: 30.98%\n",
      "- McGowan, Miss. Katherine: 68.64%\n",
      "- Collett, Mr. Sidney C Stuart: 17.13%\n",
      "- Rosenbaum, Miss. Edith Louise: 97.84%\n",
      "- Delalic, Mr. Redjo: 9.16%\n",
      "- Andersen, Mr. Albert Karvin: 3.52%\n",
      "- Finoli, Mr. Luigi: 6.76%\n",
      "- Deacon, Mr. Percy William: 17.9%\n",
      "- Howard, Mrs. Benjamin (Ellen Truelove Arman): 86.13%\n",
      "- Andersson, Miss. Ida Augusta Margareta: 50.24%\n",
      "- Head, Mr. Christopher: 32.69%\n",
      "- Mahon, Miss. Bridget Delia: 70.33%\n",
      "- Wick, Mr. George Dennick: 64.24%\n",
      "- Widener, Mrs. George Dunton (Eleanor Elkins): 100.0%\n",
      "- Thomson, Mr. Alexander Morrison: 6.3%\n",
      "- Duran y More, Miss. Florentina: 83.58%\n",
      "- Reynolds, Mr. Harold J: 11.6%\n",
      "- Cook, Mrs. (Selena Rogers): 89.56%\n",
      "- Karlsson, Mr. Einar Gervasius: 11.89%\n",
      "- Candee, Mrs. Edward (Helen Churchill Hungerford): 96.93%\n",
      "- Moubarek, Mrs. George (Omine Amenia\" Alexander)\": 45.69%\n",
      "- Asplund, Mr. Johan Charles: 10.6%\n",
      "- McNeill, Miss. Bridget: 70.31%\n",
      "- Everett, Mr. Thomas James: 4.08%\n",
      "- Hocking, Mr. Samuel James Metcalfe: 12.23%\n",
      "- Sweet, Mr. George Frederick: 20.23%\n",
      "- Willard, Miss. Constance: 98.3%\n",
      "- Wiklund, Mr. Karl Johan: 13.57%\n",
      "- Linehan, Mr. Michael: 8.2%\n",
      "- Cumings, Mr. John Bradley: 19.89%\n",
      "- Vendel, Mr. Olof Edvin: 12.55%\n",
      "- Warren, Mr. Frank Manley: 19.11%\n",
      "- Baccos, Mr. Raffull: 30.57%\n",
      "- Hiltunen, Miss. Marta: 88.54%\n",
      "- Douglas, Mrs. Walter Donald (Mahala Dutton): 96.72%\n",
      "- Lindstrom, Mrs. Carl Johan (Sigrid Posse): 96.81%\n",
      "- Christy, Mrs. (Alice Frances): 90.49%\n",
      "- Spedden, Mr. Frederic Oakley: 64.55%\n",
      "- Hyman, Mr. Abraham: 6.37%\n",
      "- Johnston, Master. William Arthur Willie\"\": 3.22%\n",
      "- Kenyon, Mr. Frederick R: 28.08%\n",
      "- Karnes, Mrs. J Frank (Claire Bennett): 86.92%\n",
      "- Drew, Mr. James Vivian: 9.6%\n",
      "- Hold, Mrs. Stephen (Annie Margaret Hill): 87.58%\n",
      "- Khalil, Mrs. Betros (Zahie Maria\" Elias)\": 46.19%\n",
      "- West, Miss. Barbara J: 95.77%\n",
      "- Abrahamsson, Mr. Abraham August Johannes: 12.45%\n",
      "- Clark, Mr. Walter Miller: 99.4%\n",
      "- Salander, Mr. Karl Johan: 8.61%\n",
      "- Wenzel, Mr. Linhart: 5.68%\n",
      "- MacKay, Mr. George William: 6.52%\n",
      "- Mahon, Mr. John: 8.25%\n",
      "- Niklasson, Mr. Samuel: 7.25%\n",
      "- Bentham, Miss. Lilian W: 88.9%\n",
      "- Midtsjo, Mr. Karl Albert: 11.91%\n",
      "- de Messemaeker, Mr. Guillaume Joseph: 4.12%\n",
      "- Nilsson, Mr. August Ferdinand: 11.82%\n",
      "- Wells, Mrs. Arthur Henry (Addie\" Dart Trevaskis)\": 88.7%\n",
      "- Klasen, Miss. Gertrud Emilia: 78.49%\n",
      "- Portaluppi, Mr. Emilio Ilario Giuseppe: 13.26%\n",
      "- Lyntakoff, Mr. Stanko: 6.36%\n",
      "- Chisholm, Mr. Roderick Robert Crispin: 5.85%\n",
      "- Warren, Mr. Charles William: 6.52%\n",
      "- Howard, Miss. May Elizabeth: 54.31%\n",
      "- Pokrnic, Mr. Mate: 15.95%\n",
      "- McCaffry, Mr. Thomas Francis: 18.47%\n",
      "- Fox, Mr. Patrick: 8.25%\n",
      "- Clark, Mrs. Walter Miller (Virginia McDowell): 100.0%\n",
      "- Lennon, Miss. Mary: 70.28%\n",
      "- Saade, Mr. Jean Nassr: 9.7%\n",
      "- Bryhl, Miss. Dagmar Jenny Ingeborg : 83.05%\n",
      "- Parker, Mr. Clifford Richard: 15.48%\n",
      "- Faunthorpe, Mr. Harry: 10.01%\n",
      "- Ware, Mr. John James: 12.09%\n",
      "- Oxenham, Mr. Percy Thomas: 18.75%\n",
      "- Oreskovic, Miss. Jelka: 57.26%\n",
      "- Peacock, Master. Alfred Edward: 81.07%\n",
      "- Fleming, Miss. Honora: 70.31%\n",
      "- Touma, Miss. Maria Youssef: 72.51%\n",
      "- Rosblom, Miss. Salli Helena: 57.07%\n",
      "- Dennis, Mr. William: 5.62%\n",
      "- Franklin, Mr. Charles (Charles Fardon): 6.66%\n",
      "- Snyder, Mr. John Pillsbury: 60.87%\n",
      "- Mardirosian, Mr. Sarkis: 9.69%\n",
      "- Ford, Mr. Arthur: 6.3%\n",
      "- Rheims, Mr. George Alexander Lucien: 30.57%\n",
      "- Daly, Miss. Margaret Marcella Maggie\"\": 70.16%\n",
      "- Nasr, Mr. Mustafa: 9.69%\n",
      "- Dodge, Dr. Washington: 16.8%\n",
      "- Wittevrongel, Mr. Camille: 5.14%\n",
      "- Angheloff, Mr. Minko: 8.52%\n",
      "- Laroche, Miss. Louise: 99.61%\n",
      "- Samaan, Mr. Hanna: 3.28%\n",
      "- Loring, Mr. Joseph Holland: 26.42%\n",
      "- Johansson, Mr. Nils: 6.84%\n",
      "- Olsson, Mr. Oscar Wilhelm: 6.02%\n",
      "- Malachard, Mr. Noel: 12.5%\n",
      "- Phillips, Mr. Escott Robert: 9.45%\n",
      "- Pokrnic, Mr. Tome: 9.19%\n",
      "- McCarthy, Miss. Catherine Katie\"\": 70.31%\n",
      "- Crosby, Mrs. Edward Gifford (Catherine Elizabeth Halstead): 97.76%\n",
      "- Allison, Mr. Hudson Joshua Creighton: 99.52%\n",
      "- Aks, Master. Philip Frank: 87.96%\n",
      "- Hays, Mr. Charles Melville: 14.69%\n",
      "- Hansen, Mrs. Claus Peter (Jennie L Howard): 48.74%\n",
      "- Cacic, Mr. Jego Grga: 14.14%\n",
      "- Vartanian, Mr. David: 24.52%\n",
      "- Sadowitz, Mr. Harry: 6.51%\n",
      "- Carr, Miss. Jeannie: 67.95%\n",
      "- White, Mrs. John Stuart (Ella Holmes): 98.4%\n",
      "- Hagardon, Miss. Kate: 68.54%\n",
      "- Spencer, Mr. William Augustus: 35.27%\n",
      "- Rogers, Mr. Reginald Harry: 22.43%\n",
      "- Jonsson, Mr. Nils Hilding: 7.95%\n",
      "- Jefferys, Mr. Ernest Wilfred: 5.89%\n",
      "- Andersson, Mr. Johan Samuel: 8.61%\n",
      "- Krekorian, Mr. Neshan: 16.79%\n",
      "- Nesson, Mr. Israel: 15.76%\n",
      "- Rowe, Mr. Alfred G: 39.98%\n",
      "- Kreuchen, Miss. Emilie: 100.0%\n",
      "- Assam, Mr. Ali: 11.35%\n",
      "- Becker, Miss. Ruth Elizabeth: 78.97%\n",
      "- Rosenshine, Mr. George (Mr George Thorne\")\": 17.85%\n",
      "- Clarke, Mr. Charles Valentine: 9.13%\n",
      "- Enander, Mr. Ingvar: 17.0%\n",
      "- Davies, Mrs. John Morgan (Elizabeth Agnes Mary White) : 89.59%\n",
      "- Dulles, Mr. William Crothers: 31.52%\n",
      "- Thomas, Mr. Tannous: 9.7%\n",
      "- Nakid, Mrs. Said (Waika Mary\" Mowad)\": 41.6%\n",
      "- Cor, Mr. Ivan: 7.92%\n",
      "- Maguire, Mr. John Edward: 38.85%\n",
      "- de Brito, Mr. Jose Joaquim: 13.49%\n",
      "- Elias, Mr. Joseph: 4.09%\n",
      "- Denbury, Mr. Herbert: 6.36%\n",
      "- Betros, Master. Seman: 9.69%\n",
      "- Fillbrook, Mr. Joseph Charles: 23.58%\n",
      "- Lundstrom, Mr. Thure Edvin: 6.06%\n",
      "- Sage, Mr. John George: 0.39%\n",
      "- Cardeza, Mrs. James Warburton Martinez (Charlotte Wardle Drake): 100.0%\n",
      "- van Billiard, Master. James William: 4.92%\n",
      "- Abelseth, Miss. Karen Marie: 57.41%\n",
      "- Botsford, Mr. William Hull: 15.76%\n",
      "- Whabee, Mrs. George Joseph (Shawneene Abi-Saab): 42.18%\n",
      "- Giles, Mr. Ralph: 16.05%\n",
      "- Walcroft, Miss. Nellie: 90.04%\n",
      "- Greenfield, Mrs. Leo David (Blanche Strouse): 96.68%\n",
      "- Stokes, Mr. Philip Joseph: 16.65%\n",
      "- Dibden, Mr. William: 14.06%\n",
      "- Herman, Mr. Samuel: 4.11%\n",
      "- Dean, Miss. Elizabeth Gladys Millvina\"\": 67.95%\n",
      "- Julian, Mr. Henry Forbes: 33.68%\n",
      "- Brown, Mrs. John Murray (Caroline Lane Lamson): 98.43%\n",
      "- Lockyer, Mr. Edward: 6.37%\n",
      "- O'Keefe, Mr. Patrick: 8.25%\n",
      "- Lindell, Mrs. Edvard Bengtsson (Elin Gerda Persson): 55.12%\n",
      "- Sage, Master. William Henry: 2.84%\n",
      "- Mallet, Mrs. Albert (Antoinette Magnin): 73.91%\n",
      "- Ware, Mrs. John James (Florence Louise Long): 90.04%\n",
      "- Strilic, Mr. Ivan: 7.43%\n",
      "- Harder, Mrs. George Achilles (Dorothy Annan): 97.57%\n",
      "- Sage, Mrs. John (Annie Bullen): 13.58%\n",
      "- Caram, Mr. Joseph: 5.86%\n",
      "- Riihivouri, Miss. Susanna Juhantytar Sanni\"\": 18.76%\n",
      "- Gibson, Mrs. Leonard (Pauline C Boeson): 96.85%\n",
      "- Pallas y Castello, Mr. Emilio: 13.8%\n",
      "- Giles, Mr. Edgar: 18.8%\n",
      "- Wilson, Miss. Helen Alice: 99.98%\n",
      "- Ismay, Mr. Joseph Bruce: 1.0%\n",
      "- Harbeck, Mr. William H: 10.06%\n",
      "- Dodge, Mrs. Washington (Ruth Vidaver): 96.96%\n",
      "- Bowen, Miss. Grace Scott: 100.0%\n",
      "- Kink, Miss. Maria: 57.29%\n",
      "- Cotterill, Mr. Henry Harry\"\": 18.8%\n",
      "- Hipkins, Mr. William Edward: 32.86%\n",
      "- Asplund, Master. Carl Edgar: 15.99%\n",
      "- O'Connor, Mr. Patrick: 8.25%\n",
      "- Foley, Mr. Joseph: 8.73%\n",
      "- Risien, Mrs. Samuel (Emma): 55.17%\n",
      "- McNamee, Mrs. Neal (Eileen O'Leary): 45.95%\n",
      "- Wheeler, Mr. Edwin Frederick\"\": 14.26%\n",
      "- Herman, Miss. Kate: 77.3%\n",
      "- Aronsson, Mr. Ernst Axel Algot: 9.93%\n",
      "- Ashby, Mr. John: 7.33%\n",
      "- Canavan, Mr. Patrick: 9.02%\n",
      "- Palsson, Master. Paul Folke: 28.01%\n",
      "- Payne, Mr. Vivian Ponsonby: 82.35%\n",
      "- Lines, Mrs. Ernest H (Elizabeth Lindsey James): 98.66%\n",
      "- Abbott, Master. Eugene Joseph: 5.87%\n",
      "- Gilbert, Mr. William: 9.75%\n",
      "- Kink-Heilmann, Mr. Anton: 3.49%\n",
      "- Smith, Mrs. Lucien Philip (Mary Eloise Hughes): 99.35%\n",
      "- Colbert, Mr. Patrick: 9.32%\n",
      "- Frolicher-Stehli, Mrs. Maxmillian (Margaretha Emerentia Stehli): 95.62%\n",
      "- Larsson-Rondberg, Mr. Edvard A: 11.26%\n",
      "- Conlon, Mr. Thomas Henry: 8.13%\n",
      "- Bonnell, Miss. Caroline: 100.0%\n",
      "- Gale, Mr. Harry: 10.76%\n",
      "- Gibson, Miss. Dorothy Winifred: 98.72%\n",
      "- Carrau, Mr. Jose Pedro: 36.68%\n",
      "- Frauenthal, Mr. Isaac Gerald: 28.57%\n",
      "- Nourney, Mr. Alfred (Baron von Drachstedt\")\": 27.94%\n",
      "- Ware, Mr. William Jeffery: 17.68%\n",
      "- Widener, Mr. George Dunton: 99.71%\n",
      "- Riordan, Miss. Johanna Hannah\"\": 70.31%\n",
      "- Peacock, Miss. Treasteall: 66.43%\n",
      "- Naughton, Miss. Hannah: 70.31%\n",
      "- Minahan, Mrs. William Edward (Lillian E Thorpe): 98.01%\n",
      "- Henriksson, Miss. Jenny Lovisa: 55.71%\n",
      "- Spector, Mr. Woolf: 6.3%\n",
      "- Oliva y Ocana, Dona. Fermina: 99.28%\n",
      "- Saether, Mr. Simon Sivertsen: 5.37%\n",
      "- Ware, Mr. Frederick: 6.3%\n",
      "- Peter, Master. Michael J: 3.12%\n",
      "Número total de datos:  418\n",
      "Número de mujeres:  152\n",
      "Número de hombres:  266\n",
      "Número de niños:  32\n",
      "Número pasajeros primera clase:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilidad de supervivencia: \\n\")\n",
    "\n",
    "Imprimir_Prediccion_Vida(datos_pre['Name'], datos_pre['Sex'], datos_pre['Age'], datos_pre['Fare'], model.predict(entrada_pre) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorización de los pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos medios por entrada\n",
      "------------------------\n",
      " Característica    Peso \n",
      "------------------------\n",
      "- Pclass: [-0.03665774]\n",
      "- Sex: [-0.01449199]\n",
      "- Age: [-0.0138398]\n",
      "- Fare: [-0.02164296]\n",
      "- Embarked: [-0.0069057]\n"
     ]
    }
   ],
   "source": [
    "pesos_entrada = model.get_weights()[0]\n",
    "\n",
    "nombres_entrada = np.array(['Pclass','Sex','Age','Fare',\n",
    "                            'Embarked',])\n",
    "\n",
    "medias = np.array([ [np.average(pesos_entrada[0])], [np.average(pesos_entrada[1])], [np.average(pesos_entrada[2])],\n",
    "                    [np.average(pesos_entrada[3])], [np.average(pesos_entrada[4])]])\n",
    "\n",
    "print(\"Pesos medios por entrada\")\n",
    "print(\"------------------------\")\n",
    "print(\" Característica    Peso \")\n",
    "print(\"------------------------\")\n",
    "\n",
    "Imprimir_Medias_Pesos(nombres_entrada, medias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
