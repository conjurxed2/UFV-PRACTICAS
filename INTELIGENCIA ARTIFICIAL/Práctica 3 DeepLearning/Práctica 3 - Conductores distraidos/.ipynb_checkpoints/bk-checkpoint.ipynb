{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 3. Práctica 3 - DNN para clasificar imágenes\n",
    "## Preparación de entorno\n",
    "### Gonzalo de las Heras\n",
    "### Jorge de la Fuente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar librerías de código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gonzalo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import ticker\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from IPython.display import Image, display\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clases = np.array([\"c0: safe driving\",\"c1: texting - right\",\"c2: talking on the phone - right\",\"c3: texting - left\",\"c4: talking on the phone - left\",\"c5: operating the radio\",\"c6: drinking\",\"c7: reaching behind\",\"c8: hair and makeup\",\"c9: talking to passenger\"])\n",
    "\n",
    "Cargar_modelo_desde_fichero = False\n",
    "Epochs = 4\n",
    "Batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Función para sacar una gráfica con los probabilidad de que una iamgen pertenezca a una clase.\n",
    "Parámetros:\n",
    "    - Datos: Vector de probabilidades.\n",
    "\"\"\"\n",
    "def GraficaPorcentajes(Datos):   \n",
    "\n",
    "    N = 10\n",
    "    men_means = Datos * 100\n",
    "    ind = np.arange(N)  \n",
    "    width = 0.35\n",
    "    \n",
    "    posicion = np.argmax(Datos)\n",
    "    \n",
    "    print(\"Con un \", round(men_means[posicion], 1), \"% es un/a \", Clases[posicion])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    rects1 = ax.bar(ind, men_means, width, color='b')\n",
    "    \n",
    "    figure_title = \"Predicción\"\n",
    "\n",
    "    plt.text(0.5, 1.15, figure_title,\n",
    "             horizontalalignment='center',\n",
    "             fontsize=20,\n",
    "             transform = ax.transAxes)\n",
    "    \n",
    "    ax.set_ylabel(\"Probabilidad\")\n",
    "    ax.set_ylim([0,100])\n",
    "    ax.set_xticks(ind + width/ 2)\n",
    "    ax.set_xticklabels((\"c0\",\"c1\", \"c2\", \"c3\", \"c4\", \"c5\", \"c6\", \"c7\", \"c8\", \"c9\"))\n",
    "    def autolabel(rects):\n",
    "        \"\"\"\n",
    "        Attach a text label above each bar displaying its height\n",
    "        \"\"\"\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                    '%d' % int(height),\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "    autolabel(rects1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Función para convertir los ficheros de imágenes en array de píxeles con un tamaño\n",
    "redimensionado para mejorar el rendimiento del programa.\n",
    "Parámetros:\n",
    "    - file_path: Dirección de los ficheros.\n",
    "Devuelve:\n",
    "    - La array de píxeles de la imagen redimensionada.\n",
    "\"\"\"\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "    b,g,r = cv2.split(img)\n",
    "    img2 = cv2.merge([r,g,b])\n",
    "    return cv2.resize(img2, (128, 96), interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Función leer todas las imágenes y juntarlas en una una array de píxeles:\n",
    "    - images: Dirección de los ficheros.\n",
    "Devuelve:\n",
    "    - La array de píxeles de todas las imágenes.\n",
    "\"\"\"\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, 3, 128, 96), dtype=np.uint8)\n",
    "\n",
    "    for i, image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image.T\n",
    "        if i%1000 == 0: \n",
    "            print(\"Procesados \", i, \" archivos de \", count)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Función para predecir las imágenes propuestas almacenadas en ficheros externos.\n",
    "Parámetros:\n",
    "    - NumFicheros: Número de ficheros a cargar y predecir.\n",
    "ATENCIÓN!!!\n",
    "    - El formato del nombre de los ficheros debe de ser image(NÚMERO).txt\n",
    "Devuelve:\n",
    "    - Modelo de keras de la red neuronal.\n",
    "\"\"\"\n",
    "def CrearModelo():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # Imágenes de 128 x 96\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(3, 128, 96), activation=\"relu\"))\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "    # MLP\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5)) #Dropout en MLP, recomendado por chollet.    \n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5)) #Dropout en MLP, recomendado por chollet.\n",
    "    model.add(Dense(10, activation = \"softmax\"))\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(lr=1e-4), metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Funcion para entrenar un modelo de red neuronal pasado por parámetro y guardarla en un fichero.\n",
    "Parámetros:\n",
    "    - Model: Modelo de red neuronal a entrenar.\n",
    "\"\"\"\n",
    "def EntrenarModelo(KerasModel):    \n",
    "        \n",
    "    print(Model.summary())\n",
    "\n",
    "    # Parada prematura para evitar sobreentrenamiento\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=0, verbose=1, mode='auto')\n",
    "\n",
    "    # Entrenamiento del modelo\n",
    "    datos_entrenamiento = KerasModel.fit(Conjunto_Entrenamiento, Etiquetas, batch_size=Batch_size, epochs=Epochs, validation_split=0.2, verbose=1, shuffle=True, callbacks=[early_stopping])\n",
    "    \n",
    "    # Gráfica evolución de loss\n",
    "    plt.plot(datos_entrenamiento.history['loss'], label='loss')\n",
    "    plt.plot(datos_entrenamiento.history['val_loss'], label='val_loss')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # Gráfica evolución de acc\n",
    "    plt.plot(datos_entrenamiento.history['acc'], label='acc')\n",
    "    plt.plot(datos_entrenamiento.history['val_acc'], label='val_acc')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # Guardado en disco del modelo\n",
    "    KerasModel.save('red_conv_conductores.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Función para generar la salida espera para la red neuronal.\n",
    "Devuelve:\n",
    "    - Las etiquetas de salida de la red neuronal.\n",
    "\"\"\"\n",
    "def GenerarEtiquetas():\n",
    "    datos = pd.read_csv('driver_imgs_list.csv')\n",
    "\n",
    "    etiquetas = []\n",
    "\n",
    "    for i in range(0, len(Imagenes_Entrenamiento)):\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Generando tags... \", i, \" de \", len(Imagenes_Entrenamiento))\n",
    "\n",
    "        nombre_fichero = Imagenes_Entrenamiento[i].split(\"/\")    \n",
    "        \n",
    "        fila = datos.loc[datos['img'] == nombre_fichero[2]]\n",
    "\n",
    "        clase = np.array(fila[\"classname\"])\n",
    "\n",
    "        if clase == \"c0\":\n",
    "            etiquetas.append(0)\n",
    "        elif clase == \"c1\":\n",
    "            etiquetas.append(1)\n",
    "        elif clase == \"c2\":\n",
    "            etiquetas.append(2)    \n",
    "        elif clase == \"c3\":\n",
    "            etiquetas.append(3)\n",
    "        elif clase == \"c4\":\n",
    "            etiquetas.append(4)\n",
    "        elif clase == \"c5\":\n",
    "            etiquetas.append(5)    \n",
    "        elif clase == \"c6\":\n",
    "            etiquetas.append(6)    \n",
    "        elif clase == \"c7\":\n",
    "            etiquetas.append(7)    \n",
    "        elif clase == \"c8\":\n",
    "            etiquetas.append(8)   \n",
    "        elif clase == \"c9\":\n",
    "            etiquetas.append(9)   \n",
    "        \n",
    "    etiquetas = np_utils.to_categorical(etiquetas)\n",
    "    return etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Programa principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesados  0  archivos de  22424\n",
      "Procesados  1000  archivos de  22424\n",
      "Procesados  2000  archivos de  22424\n",
      "Procesados  3000  archivos de  22424\n",
      "Procesados  4000  archivos de  22424\n",
      "Procesados  5000  archivos de  22424\n",
      "Procesados  6000  archivos de  22424\n",
      "Procesados  7000  archivos de  22424\n",
      "Procesados  8000  archivos de  22424\n",
      "Procesados  9000  archivos de  22424\n",
      "Procesados  10000  archivos de  22424\n",
      "Procesados  11000  archivos de  22424\n",
      "Procesados  12000  archivos de  22424\n",
      "Procesados  13000  archivos de  22424\n",
      "Procesados  14000  archivos de  22424\n"
     ]
    }
   ],
   "source": [
    "Dir_Entrenamiento = 'imgs/train/'\n",
    "Dir_Test = 'imgs/test/'\n",
    "\n",
    "# Recogida imágenes\n",
    "Imagenes_Entrenamiento = [Dir_Entrenamiento+i for i in os.listdir(Dir_Entrenamiento)] \n",
    "Imagenes_Test =  [Dir_Test+i for i in os.listdir(Dir_Test)]\n",
    "\n",
    "# Se barajan imágenes\n",
    "random.shuffle(Imagenes_Entrenamiento)\n",
    "\n",
    "# Se coge un subconjunto de las imágenes de test\n",
    "Imagenes_Test =  Imagenes_Test[:50]\n",
    "\n",
    "# Se transforman las imágenes en arrays de píxeles\n",
    "Conjunto_Entrenamiento = prep_data(Imagenes_Entrenamiento)\n",
    "Conjunto_Test = prep_data(Imagenes_Test)\n",
    "\n",
    "# Se generan las etiquetas de salida de la red\n",
    "Etiquetas = GenerarEtiquetas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Cargar_modelo_desde_fichero is False:\n",
    "    Model = CrearModelo()\n",
    "    Model = EntrenarModelo(Model)\n",
    "    \n",
    "# Carga del modelo desde fichero\n",
    "Model = load_model(\"red_conv_conductores.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Dir_Pruebas = 'imgs/prueba/'\n",
    "\n",
    "# Recogida imágenes\n",
    "Imagenes_Prueba =  [Dir_Pruebas+i for i in os.listdir(Dir_Pruebas)]\n",
    "\n",
    "# Se transforman las imágenes en arrays de píxeles\n",
    "ConjuntoPrueba = prep_data(Imagenes_Prueba)\n",
    "\n",
    "# Predicción\n",
    "Predicciones_Prueba = Model.predict(ConjuntoPrueba, verbose=0)\n",
    "\n",
    "# Bucle de mostrado\n",
    "for i in range(0,len(Imagenes_Prueba)):\n",
    "    print(\"==========================================================\")\n",
    "    print(\"==========================================================\")\n",
    "    print(\"==========================================================\")\n",
    "    print(\"IMAGEN: \", Imagenes_Prueba[i])\n",
    "    \n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(ConjuntoPrueba[i].T)\n",
    "    plt.show()    \n",
    "    \n",
    "    display(Image(filename=Imagenes_Prueba[i]))\n",
    "    \n",
    "    print(\"--------\")\n",
    "    \n",
    "    GraficaPorcentajes(Predicciones_Prueba[i])    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
